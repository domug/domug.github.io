I")<p>해당 포스트에서는 A/B Test에서 아웃라이어의 처리가 필요한 이유와 이를 위한 몇가지 방법론들을 살펴볼 예정이다.</p>

<p> </p>

<hr />

<h1 id="1-outliers-in-ab-test">1. Outliers in A/B Test</h1>

<p>본격적인 내용을 살펴보기에 앞서, 아웃라이어의 의미에 대해서 간략하게 생각해보도록 하자.</p>

<p>통계학에서 <strong>“아웃라이어”</strong>란, 대다수의 <strong>“정상적인”</strong> 데이터와 그 성질이 사뭇 다른 데이터를 의미한다. 따라서 컴퓨터 과학, 머신러닝, 통계학의 범주를 아우르는 <strong>아웃라이어 탐지 과제</strong>는 주어진 데이터로부터 정상적인 패턴과 비정상적인 패턴을 구분하는 것이 주된 관심사라고 할 수 있다.</p>

<p>한편, 아웃라이어를 정의하는 것은 그리 간단하지만은 않다. 가령, 대한민국 남성의 평균 키가 약 170cm 중반이라는 점을 감안할 때, 일반적으로 <strong>키가</strong> <strong>200cm가 넘어가는 남성</strong>들은 아웃라이어라고 판단할 수 있을 것이다. 한편, 만약 우리의 관심사가 <strong>농구 선수</strong>들의 키라고 한다면 이 때는 키가 200cm가 넘어가는 남성들을 아웃라이어라고 판단하기는 다소 어려울 수 있다.</p>

<p>이처럼 아웃라이어 탐지는 주어진 데이터의 맥락을 고려해야 한다는 특징이 있다. 이러한 맥락에서 아웃라이어는 크게 <strong>“절대적 아웃라이어”</strong>와 <strong>“상대적 아웃라이어”</strong>의 범주로 구분될 수 있다.</p>

<p>자 이제 A/B Test의 맥락에서 아웃라이어 처리의 목적에 대해서 살펴보자. A/B Test는 대조군과 시험군 간의 <strong>“평균적인 경향성”</strong>을 파악하기 위해 수행된다. 즉, 다른 모든 조건이 동일할 때 특정한 기능을 적용 받은 사람들이 그렇지 않은 사람들에 비해 어떠한 차이가 있는지를 파악하는 것이 일차적인 목표라고 할 수 있다. 이러한 맥락에서 A/B Test에서의 아웃라이어 탐지는 그 성격상 “상대적 아웃라이어”를 찾고, 해당 값들을 적절히 처리하기 위한 목적으로 수행된다.</p>

<p>그렇다면 A/B Test에서 아웃라이어를 처리하는 것이 왜 중요할까? 설명의 편의를 위해 가장 일반적인 연속형 지표의 모평균에 대한 이표본 t검정 (two sample t-test) 를 바탕으로 논의를 이어가겠다. 이 때, 실험에 사용되는 검정통계량은 다음과 같다.</p>

<center>

$$
t_{df} = \frac{(\bar X_1 - \bar X_2) - (\mu_1 - \mu_2)}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}
$$

</center>

<p> </p>

<p>이를 바탕으로, 통계적 가설 검정은 해당 검정통계량이 기각역보다 클 경우 귀무 가설을 기각하고 두 그룹간 차이가 통계적으로 유의미하다는 결론을 내리는 방식으로 진행된다. 다시 말해, 실험의 유의성을 주장하기 위해서 우리는 (일반적으로) <strong>더 큰 검정통계량을 값을 얻고자 하는 것이다</strong>.</p>

<p>이러한 맥락에서 검정통계량 $t_{df}$ 를 좀 더 구체적으로 뜯어보도록 하자. 여기서 중요한 것은 해당 식의 <strong>분모</strong>인데, 이는 대조군과 시험군의 표본 분산 $s_1^2, s_2^2$과 샘플 사이즈 $n_1, n_2$로 구성되어 있다는 점을 알 수 있다. 일반적인 A/B Test에서 수집될 샘플 사이즈는 실험의 기획 단계에서 정해지기 때문에 $n_1$과 $n_2$는 우리의 주된 관심사는 아니다.</p>

<p>한편, 각 집단별 표본 분산 $s_1^2, s_2^2$는 수집된 데이터에 영향을 받게 되는데, 구체적으로 <strong>$s_1^2, s_2^2$의 값이 작아지면 작아질 수록 전체적인 검정통계량 $t_{df}$의 값이 커지게 된다</strong>. 그렇기 때문에 수집된 데이터의 분산을 줄이는 것은 우리의 분명한 관심사가 되는 것이다.</p>

<p>그렇다면 어떻게 데이터의 분산을 줄일 수 있을까? 분산은 데이터의 변동성을 측정하는 지표이다. 그리고 <strong>아웃라이어의 존재는 종종 데이터의 분포를 불안정하게 만들어 분산을 증가시킨다 (inflation of variance)</strong>. 따라서 적절히 아웃라이어를 제거해주는 작업은 실험의 비용 측면에서 상당히 중요한 과제라고 할 수 있다.</p>

<p>이 밖에도 모평균에 대한 검정에서 아웃라이어를 처리하는 것은 정규 근사의 측면에서도 의미가 있다. 일반적으로 온라인 A/B Test에서 수집되는 웹 데이터는 양의 왜도 (skewness) 가 상당히 크다는 점에서, 극단적인 아웃라이어를 제거하는 것을 통해 중심 극한 정리가 작동하기 위한 표본 평균의 정규 근사 정도를 보장할 수 있다.</p>

<p>한편, 그럼에도 불구하고 아웃라이어를 어떠한 방식으로든 처리한다는 것은 수집된 데이터에 사후적인 변형을 가하는 점이라는 사실을 항상 유념해야 한다. 잘못된 아웃라이어 처리는 실험의 결과를 왜곡할 수 있기 때문에 아웃라이어 처리 로직에 대한 충분한 정당화가 가능해야 할 것이다. 이러한 맥락에서 온라인 A/B Test에서 흔히 활용되는 몇가지 아웃라이어 처리 방법론들에 대해 살펴보도록 하겠다.</p>

<p> </p>

<p> </p>

<hr />

<h1 id="2-strategies">2. Strategies</h1>

<p>일반적인 아웃라이어 탐지 테스크와는 다르게, 온라인 A/B Test에서의 아웃라이어 처리의 특징은 거의 대부분의 경우 <strong>일차원의 데이터를 다룬다는 점이다 (시험군 vs 대조군)</strong>. 그렇기 때문에 학계에서 연구되는 (주로 고차원 데이터에서의) 복잡한 아웃라이어 탐지 방법론과는 다르게 비교적 간단한 통계 방법론도 상당히 효과적으로 활용될 여지가 있다.</p>

<p>이러한 맥락에서 온라인 A/B Test에서 활용될 수 있는 아웃라이어 처리 방법론 몇가지를 간략힌 살펴보도록 하겠다.</p>

<p> </p>

<h3 id="quantile-winsorization">Quantile Winsorization</h3>

<p>통계학에서 <strong>“winsorizing”</strong>, 또는 <strong>“capping”</strong> 이란, 주어진 데이터에서 <strong>일정한 기준점을 넘어가는 값을 특정한 값으로 대체하는 것이다</strong>. 이와 관련해 “<strong>quantile winsorization</strong>“은 해당 기준점을 데이터에서의 분위 수로 지정해 아웃라이어를 처리한다.</p>

<p>해당 방법은 개념적으로도, 구현상으로도 상당히 간단하기 때문에 쉽게 적용할 수 있다는 장점이 있으나, 문제는 해당 방법을 적용할 경우 데이터의 형태를 고려하지 않은채 항상 일정한 %의 데이터가 아웃라이어로 간주되어 대체된다는 점이다. 가령, 아웃라이어가 없는 깨끗한 데이터의 경우 정상적인 데이터가 잘려나가는 이슈가 발생할 수 있다. 이처럼 데이터의 분포 형태를 고려하지 않은채 아웃라이어를 처리하는 방법은 안전성의 측면에서 다소 우려가 있을 수 있다.</p>

<p> </p>

<center>
  <img src="/images/abtest/41.png" width="500" height="300" /> 
 <br />
 <em><span style="color:grey">5% quantile winsorization 예시</span></em>
</center>

<p> </p>

<h3 id="3-sigma-rule">3-$\sigma$ Rule</h3>

<p>3-$\sigma$ rule 방법은 정규분포의 성질을 바탕으로 아웃라이어를 정의한다.</p>

<p>정규 분포의 누적 확률 밀도 함수 (i.e. cdf) 를 바탕으로 할 때, 우리는 다음과 같이 평균 $\mu$ 를 기준으로 표준 편차 $\sigma$의 값에 따라 $[\mu - 3\sigma , \mu + 3\sigma]$ 의 범위 안에 약 99.7%의 확률 밀도가 존재하는 것을 이론적으로 알고 있다.</p>

<p> </p>

<center>
  <img src="/images/abtest/42.png" width="500" height="300" /> 
 <br />
 <em><span style="color:grey"></span></em>
</center>

<p> </p>

<p>따라서 정규분포를 따르는 종 모양의 데이터에 대해 $\mu \pm 3\sigma$ 의 기준점을 세울 경우, 해당 범위에 포함되지 않는 약 0.3%의 데이터를 우리는 자연스레 아웃라이어로 간주할 수 있다.</p>

<p>이처럼 3-$\sigma$ rule은 <strong>경험 법칙 (rule of thumb)</strong>에 의거한 방법인데, 그 이론적 정당성은 모평균에 대한 검정에서 충분한 샘플 사이즈가 보장될 경우 중심극한정리가 작용한다는 것에 기반한다. 그렇기 때문에 많은 실험 플랫폼에서 해당 방법을 아웃라이어 처리에 활용하고 있다. (참고 - <a href="https://support.optimizely.com/hc/en-us/articles/4410289414413-How-Optimizely-Handles-Outliers">Optimizely</a>)</p>

<p>한편, 해당 방법 역시 완벽한 것은 아니다. 비록 구현이 간단하다는 장점이 있으나, 대부분의 온라인 웹 데이터의 경우 앞서 언급한 것처럼 양의 왜도가 상당하기 때문에 데이터의 오리지널 분포가 완벽한 종모양을 따르는 경우는 거의 없다. 따라서 실제로 3-$\sigma$ rule이 어느 정도 유효하게 작용하기 위해서는 수집된 데이터에 대한 로그 변환 또는 <a href="https://towardsdatascience.com/box-cox-transformation-explained-51d745e34203">Box-cox 변환</a> 등의 추가적인 밑작업이 필요할 수 있다.</p>

<p> </p>

<h3 id="cuped-microsoft">CUPED (Microsoft)</h3>

<p>앞서 살펴본 두 방법과는 다르게, 2013년에 마이크로소프트에서 발표한 <a href="https://exp-platform.com/Documents/2013-02-CUPED-ImprovingSensitivityOfControlledExperiments.pdf">CUPED (Controlled-experiment Using Pre-Existing Data)</a> 라는 방법론은 좀 더 까다로운 통계적 디테일을 포함하고 있다.</p>

<p>해당 방법론의 핵심적인 아이디어는,</p>

<p> </p>

<h3 id="otpsm-yahoo">OTPSM (Yahoo)</h3>

<p> </p>

<p> </p>

<hr />

<p>&lt;/center&gt;</p>

<p> </p>

<hr />

<h1 id="reference">Reference</h1>

<ul>
  <li>https://www.dynamicyield.com/lesson/outliers-detection/</li>
  <li>https://towardsdatascience.com/68-95-99-7-the-three-sigma-rule-of-thumb-used-in-power-bi-59cd50b242e2</li>
  <li>https://uxplanet.org/how-to-clean-ab-testing-data-before-analysis-113e6bfeb164</li>
  <li></li>
</ul>

:ET