I"ª<h3 id="previous-posts">Previous Posts</h3>

<p><a href="https://domug.github.io/2020/12/03/Estimation_Multicollinearity/">1. Statistical Estimation and Multicollinearity</a></p>

<p><a href="https://domug.github.io/2020/12/04/Ridge_Lasso/">2. Variable Selection Methods</a></p>

<p><a href="https://domug.github.io/2020/12/05/PCA/">3. Principal Component Analysis</a></p>

<p><a href="https://domug.github.io/2020/12/06/FA/">4. Factor Analysis</a></p>

<hr />

<h1 id="cluster-analysis-ca">Cluster Analysis (CA)</h1>

<p>In this post, we will be talking about <strong>Cluster Analysis</strong>. Until now we have seen PCA and FA which reduced dimensionality of the original data in terms of its ‚Äúvariables‚Äù. Both methods decomposed data matrix by its column vectors, so we were able to find a subset of variables that accounts for enough information of the original data. However, cluster analysis performs dimension reduction on <strong>observations</strong>, that is, by <strong>row vectors</strong>. This difference very important so always keep in mind!</p>

<p>The goal of cluster analysis is to find groups or clusters that can ‚Äúadequately‚Äù separate and group the observations. Since the word ‚Äúadequately‚Äù is a little vague in its meaning, we can define the adequacy as follows.</p>
<ul>
  <li>observations inside each clusters are similar as possible</li>
  <li>observations within different clusters are different as possible</li>
</ul>

<p>However, even in the above definition we have another ambiguousness. How are we going to measure the similarity and dissimilarity of each observations?</p>

<hr />

<p align="center">
	<img width="700" height="500" src="/images/fa/result_2.png" />
</p>

<hr />
:ET