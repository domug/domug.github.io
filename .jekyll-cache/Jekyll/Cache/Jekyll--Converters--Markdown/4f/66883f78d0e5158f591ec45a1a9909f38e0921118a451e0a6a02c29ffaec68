I"<<p>통계적 가설 검정에서 <strong>다중 검정 (Multiple Testing)</strong> 이란, 특정한 하나의 실험에서 여러번의 가설 검정을 동시에 수행하는 경우를 의미한다.</p>

<p>비록 여러번의 가설 검정을 수행하는 것 자체는 문제가 되지 않으나, 도출된 결과의 해석에 있어서 <strong>다중 검정은 1종 오류 (Type 1 error) 를 의도했던 유의수준보다 증가시킬 수 있다는 점에서 상당한 주의가 필요하다</strong>. 이러한 맥락에서, 해당 포스트에서는 다중 검정의 전체적인 개념을 소개한 다음, 이를 처리할 수 있는 통계적 방법론 몇가지를 살펴보도록 하겠다.</p>

<p> </p>

<hr />

<h2 id="1-다중-검정이-문제가-되는-이유">1. 다중 검정이 문제가 되는 이유</h2>

<p>일반적인 통계적 가설 검정 문제를 생각해보자. 특정한 한 번의 가설 검정 (i.e. 단일 검정) 절차에서 우리가 잘못된 결론을 내릴 확률, 즉 <strong>1종 오류</strong>는 유의수준 $\alpha$ 이하로 보장된다는 사실은 자명하다.</p>

<p>한편, 이러한 가설 검정 절차를 총 $m$ 번 반복한다고 가정해보자. 이 때, i-번째 귀무가설을 $H_{0i}$ 라고 정의할 경우, 전체 $m$ 개의 가설 검정 중에서 <strong>적어도 한 개 이상의 가설에 대해서 잘못된 결론을 내릴 확률</strong> (i.e. <strong>family-wise type I error</strong>) 은 역확률의 정의에 의해 다음과 같이 구해진다.</p>

<center>

$$
\begin{aligned}
P\Big(\text{at least one }H_{0i} \text{ is False} \;|\; H_{0i} \text{ is True} \Big) &amp;= 1 - P\Big(\text{all least one }H_{0i} \text{ is True} \;|\; H_{0i} \text{ is True} \Big) \\[10pt]
&amp;= 1 - (1-\alpha)^m
\end{aligned}
$$

</center>

<p> </p>

<p>이를 바탕으로 가설 검정의 개수 ($m$) 에 따른 family-wise type I error의 함수를 그래프를 다음과 같이 그릴 수 있다.</p>

<center>
  <img src="/images/abtest/11.png" width="600" height="450" /> 
 <br />
 <em><span style="color:grey"></span></em>
</center>

<p> </p>

<p>여기서 주목해야 할 점은 바로 가설 검정의 개수 $m$에 대한 family-wise type I error의 함수가 <strong>“단조증가함수”</strong>라는 점이다. 즉, 수행되는 검정이 많아지면 많아질수록 전체적으로 1종 오류가 발생할 확률 역시 점점 커진다.</p>

<p>따라서 만약 특정한 하나의 실험에서 여러 지표에 대한 가설 검정을 10번 정도만 수행할 경우, 적어도 한개 이상의 가설에 대해 잘못된 결론을 내릴 확률이 거의 <strong>40%</strong>에 육박하게 된다. 이것이 바로 다중 검정의 치명적인 문제점이라고 할 수 있다. 그리고 이는 빈도주의 가설 검정 절차의 가장 핵심적인 특징이자 장점이라고 할 수 있는 1종 오류 통제의 측면에서 실험의 결과 자체에 대한 신뢰성를 떨어뜨릴 수 있기 때문에 각별한 주의가 필요하다.</p>

<p>이처럼 다중 검정의 문제점은 위와 같이 수학적으로 증명이 된 사실이지만, 직관적인 측면에서 다중 검정의 의미를 이해하는 것은 실험을 기획하고 결과를 해석하는 분석가의 입장에서 상당히 중요하기 때문에 구체적인 예시를 바탕으로 다시 한번 살펴보도록 하겠다.</p>

<p> </p>

<h4 id="몬티-홀-문제-monty-hall-problem">몬티 홀 문제 (Monty Hall Problem)</h4>

<p><a href="https://ko.wikipedia.org/wiki/몬티_홀_문제">몬티 홀 문제</a>란 총 3개의 문 중에 하나를 선택한 다음, 그 문 뒤에 있는 경품을 가져가는 미국의 TV쇼에서 진행된 게임을 의미한다.</p>

<p>게임의 참가자에게는 문을 선택할 기회가 <strong>단 한번만</strong> 주어지며, 세개의 문 중 하나의 문 뒤에는 스포츠카가 있다.</p>

<center>
  <img src="/images/abtest/12.png" width="500" height="400" /> 
 <br />
 <em><span style="color:grey">몬티 홀 문제</span></em>
</center>

<p> </p>

<p>사실 몬티 홀 문제는 베이즈 정리를 이용한 조건부 확률의 개념을 설명할 때 흔하게 쓰이는 예시인데, 해당 포스트에서는 이러한 몬티 홀 문제의 상황을 약간 응용해서 앞서 3개의 문이 있었던 것을 <strong>20개</strong>로 늘려보도록 하겠다.</p>

<center>
  <img src="/images/abtest/13.png" width="500" height="400" /> 
 <br />
 <em><span style="color:grey"></span></em>
</center>

<p> </p>

<p>위와 같이 총 20개의 문이 있고, 그 중에서 단 하나의 문 뒤에만 경품인 스포츠카가 있다고 가정한다. 이 상황에서 게임의 참가자가 <strong>스포츠카에 당첨될 확률</strong>은 $\frac{1}{20} = 0.05$, 즉 <strong>5%</strong> 이다.</p>

<p>이제 어떤 참가자 A가 있다고 해보자. 애석하게도, A는 앞서 그에게 주어진 기회에서 꽝인 문을 선택해서 경품을 받지 못했다. 하지만 그는 경품의 위치를 재배정한 다음에 본인에게 한번만 더 기회를 달라고 호소하고 있다. 그는 “어차피 당첨 확률은 5%로 동일하기 때문에 한번의 기회가 더 주어지더라도 별 상관없지 않냐” 라는 주장을 하고 있다.</p>

<p>이러한 그의 주장은 한눈에 봐도 엉터리임이 자명하다. 비록 경품의 위치가 재배정되었다고 하더라도, 만약 A에게 문을 선택할 기회가 두번 주어진다면 그 중에 한 번이라도 경품에 당첨될 확률이 올라갈 것이라는 것은 상식적으로 너무나도 당연하기 때문이다.</p>

<p>실제로 단 한번의 게임에서 A가 경품을 탈 확률은 5%이지만, 만약 문 선택의 기회가 <strong>두번 주어진다면</strong> 경품을 탈 확률은 더이상 5%가 아니며, 앞서 확인했듯이 이는 $1 - (1-0.05)^2$ 로 거의 두배인 <strong>9.75%</strong> 가 된다.</p>

<p> </p>

<p>이제 다시 다중 검정의 내용으로 돌아가보도록 하자. 다중 검정에서 <strong>“한번의 가설 검정을 수행하는 것”</strong>은 위 예시에서 <strong>“문을 한번 선택하는 것”</strong>과 일맥상통한다. 그리고 위 예시에서 <strong>“경품이 포함된 문”</strong>은 통계적 가설 검정에서의 <strong>“1종 오류”</strong>에 대응된다.</p>

<p>애당초 A/B Test 를 진행하는 이유는 대부분의 경우 실험하고자 하는 기능에 대한 통계적 유의성을 주장하기 위함이다. 그리고 이를 위해 통계적 가설 검정을 활용하게 되는데, 당연하게도 우리는 언제나 유의수준 $\alpha$ (일반적으로 5%) 만큼의 확률로 <strong>“잘못된”</strong> 결과를 도출할 리스크를 안고 있다. 따라서 만약 앞선 예시처럼 문을 선택하는 과정을 여러번 반복하는 경우, 우연에 의해서 당첨이 될 확률이 증가해서 <strong>1종 오류</strong>에 빠지게 될 위험이 커지게 된다. 이는 결과적으로 실험의 안정성을 우리가 사전에 고려한 수준으로 보장할 수가 없게 되는 것이다.</p>

<p>사실 다중 검정은 통계학을 전공하지 않은 사람들에게는 매우 생소한 개념일 수 있어, 많은 경우 가설 검정을 여러번 하는 것이 문제가 된다는 사실 자체를 인지하지 못하는 상황이 발생할 수 있다. 이러한 측면에서 실제로 어떤 상황에서 다중 검정 문제가 발생하는지를 구체적인 예시를 통해서 살펴보도록 하겠다. 가령, 어떠한 실험에서 다음과 같이 지표들이 설정되었다고 가정하겠다.</p>

<ul>
  <li><strong>1차 유효성 평가변수 (primary metric)</strong>: “세션당 클릭수”</li>
  <li><strong>2차 유효성 평가변수 (secondary metric)</strong>: “세션당 체류시간”, “세션당 페이지뷰”</li>
</ul>

<p>가령, 유의 수준 0.05 아래에서 해당 실험의 결과로 1차 유효성 평가변수인 “세션당 클릭수”에 대해서 p-value가 <strong>0.14</strong>로 유의하지 않은 결과가 나왔다고 해보자. 반면, 2차 유효성 평가변수에 대해서도 추가적인 가설 검정을 진행해보니 이번에는 p-value가 각각 <strong>0.039, 0.042</strong> 로 유의하게 나왔다.</p>

<p>이러한 상황에서, “새로운 기능은 <strong>클릭수 개선에는 효과가 없으나</strong>, <strong>체류시간과 페이지뷰에는 효과가 있다</strong>“라고 주장할 수 있을까? 아쉽지만, 앞서 살펴본 다중 검정의 문제점 때문에 위 결론은 통계적으로 타당하지 않다. 즉, 앞서 진행된 실험에서는 1차 유효성 평가변수에 대한 인과적 결론을 도출할 수 있을 뿐, <strong>그 외의 지표에 대해서는 아무런 인과적인 결론을 얻을 수 없는 것이다.</strong></p>

<p>이처럼 서비스들이 1차 유효성 평가 변수 이외의 지표에 대한 결과를 단순히 p-value만 보고 잘못 해석하지 않도록 결과 분석 과정에서 통계학 전공자의 역할이 중요하다. 실제로 이와 같은 이유로 <em>Optimizely</em> 등 빈도주의 방식을 활용하는 실험 플랫폼들에서는 p-value를 직접 노출시키지 않는 UI를 채택한 경우가 많다.</p>

<p> </p>

<hr />

<h2 id="2-다중-검정-문제의-해결법">2. 다중 검정 문제의 해결법</h2>

<p>그렇다면 다중검정으로 인해 발생하는 문제점을 어떻게 해결할 수 있을지에 대해 살펴보자.</p>

<p> </p>

<p>우선 당연하게도, 가장 간단한 해결책은 <strong>다중검정을 하지 않는 방향으로 의사 결정 기준을 수립</strong>하는 것이다. 가령, 여러개의 평가 지표들을 1차 유효성 평가변수, 2차 유효성 평가변수, 보조 지표 등으로 <strong>우선순위</strong>를 명확하게 정의할 수 있는 경우, 최종적인 의사 결정을 1차 유효성 평가변수에 대한 결과만을 바탕으로 내리는 것이다. 이렇게 된다면 1차 유효성 평가변수 이외의 지표는 실험의 유의성 판단에 직접적으로 영향을 미치지 않는다는 점에서 유의 수준을 보정할 필요성이 없게 된다.</p>

<p> </p>

<p>두 번째 방안은 평가 지표들을 하나로 통합한 <strong>OEC (Overall Evaluation Criterion)</strong> 를 바탕으로 실험의 결론을 내리는 것이다. 이 때, OEC는 실험의 유의성을 판단함에 있어 고려될 필요가 있는 여러가지 metric들의 정보량이 하나로 합쳐진 지표이며, 개별 metric들의 특징을 충분히 반영할 수 있어야 합니다. 마찬가지로, 이와 같은 경우 확증적 가설 검정은 OEC 단 하나에 대해서만 수행된다는 점에서 다중검정의 문제가 발생하지 않는다.</p>

<p> </p>

<p>마지막 방안은 다중검정으로 인해 발생하는 문제점을 <strong>통계적으로 보정</strong>하는 것이며, 이에 대해 자세히 살펴 볼 예정이다.</p>

<p>실제 실험을 진행하다보면 불가피하게 여러번의 가설 검정을 수행해야만 하는 상황이 발생할 수 있다. 예를 들어, “유저당 평균 매출액”이라는 1차 유효성 평가변수는 고객 유지(customer retention)의 측면에서 “세션당 전환율”이라는 보조 지표가 감소하지 않았을 경우에만 의미가 있을 수 있다. 이러한 상황에서는 보조 지표와 1차 유효성 평가변수에 대해서 순차적으로 두 번의 가설 검정을 수행하되, 단 전체적인 실험에서 1종 오류가 발생할 확률이 유의수준을 넘지 않도록 <strong>개별적인 검정에서의 유의 수준을 조정</strong>해주는 방안을 생각해볼 수 있다.</p>

<p>이러한 맥락에서 흔히 사용되는 몇가지 통계 방법론을 정리하도록 하겠다. 후술할 모든 방법론은 <a href="https://en.wikipedia.org/wiki/Closed_testing_procedure">closed-testing procedure</a> 라고 불리는 통계학의 분야에서 type I error를 유의수준 이하로 컨트롤한다는 것이 이론적으로 증명된 내용들이다.</p>

<ul>
  <li>Bonferroni’s Method</li>
  <li>Sidak’s Method</li>
  <li>Holm’s Method</li>
  <li>Hochberg’s Method</li>
</ul>

<p>물론 해당 방법들은 family-wise type I error의 증가라는 다중 검정의 치명적인 문제점을 해결해주지만, 이에 대한 대가로 실험의 검정력을 낮출 수 있다는 점에서 주의가 필요하다. 그렇기 때문에 정말 필요한 상황이 아니라면 다중 검정은 최대한 지양하는 것이 최선이라고 생각한다.</p>

<p> </p>

<h3 id="bonferronis-method">Bonferroni’s Method</h3>

<p>다중검정의 문제를 해결하는 가장 기초적이고 기본이 되는 방법이다.</p>

<p><a href="https://en.wikipedia.org/wiki/Bonferroni_correction">Bonferroni 방법</a>에서는 family-wise type 1 error를 5% 이하로 통제하기 위해서 수행하려고 하는 가설 검정의 횟수가 총 $k$번인 경우, 각각의 개별적인 가설 검정을 $0.05 / k$ 의 보정된 유의수준 아래에서 검정하게 된다. 예를 들어, 유의수준 0.05의 실험에서 가설 검정 횟수에 따른 보정된 유의 수준은 다음과 같다.</p>

<center>
  <img src="/images/abtest/14.png" width="350" height="250" /> 
 <br />
 <em><span style="color:grey"></span></em>
</center>

<p>따라서 만약 총 <strong>5번</strong>의 가설 검정을 수행하고자 하는 경우, 개별적인 가설 검정에서 도출된 p-value를 0.05가 아니라 <strong>0.01과 비교</strong>해서 유의성을 판단하는 것이다.</p>

<p>Bonferroni 방법의 가장 큰 장점은 개념 자체가 매우 간단하며, <strong>어떠한 다중검정 문제에서도 family-wise type 1 error를 5% (유의수준) 이하로 통제한다</strong>는 점이다. 증명은 Bonferroni 부등식을 바탕으로 간단하게 할 수 있다. 해당 부등식의 우변을 유의 수준 $\alpha$로 고정시킬 경우, 좌변인 family-wise type I error는 항상 유의수준보다 작거나 같게 된다.</p>

<center>

$$
P(A \cup B) \leq P(A) + P(B)
$$



</center>

<p>추가적으로, “어떠한 다중검정 문제에서도”라는 말의 의미를 좀 더 구체적으로 설명드리자면, <strong>데이터의 분포</strong>와 각 <strong>개별적인 검정통계량들의 상관관계</strong>에 무관하게 적용할 수 있다는 의미입니다.</p>

<p>이렇게 별다른 가정사항이 없다는 측면에서 Bonferroni 방법은 굉장히 strong한 방법입니다.</p>

<p>하지만 단점 역시 존재합니다. 가장 큰 단점은 어떠한 경우에도 family-wise type 1 error를 유의 수준 이하로 통제하려고 하다보니, 방법론 자체가 불필요할 정도로 상당히 <strong>보수적</strong>이라는 점입니다.</p>

<p>여기서 “보수적”이란 것은 2종 오류 (type II error) 가 크다는 것이며, 따라서 Bonferroni 방법을 사용하면 <strong>검정력이 낮아지게 됩니다</strong>.</p>

<hr />

<p> </p>

<p>&lt;/center&gt;</p>

<p> </p>

<hr />

<h1 id="reference">Reference</h1>

<ul>
  <li>Casella, G., &amp; Berger, R. L. (2002). <em>Statistical inference.</em> 2nd ed. Australia ; Pacific Grove, CA: Thomson Learning.</li>
</ul>

:ET