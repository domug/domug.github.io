I";<p>해당 포스트에서는 여러개의 실험이 동시다발적으로 진행되는 플랫폼에서 (i.e. multi-layer experiments) 효율적으로 무작위 배정을 수행할 수 있는 방법에 대해서 살펴볼 예정이다.</p>

<p> </p>

<hr />

<h1 id="1-parallel-vs-non-parallel-design">1. Parallel vs Non-parallel Design</h1>

<p>A/B Test는 특정한 기능의 성과에 대한 인과적인 결론을 내리기 위해서 수행되며, 이를 위해서는 당연하게도 대조군과 시험군의 성질이 “실험하고자 하는 기능”을 제외한 모든 측면에서 비슷해야 한다. 따라서 성공적인 실험 플랫폼을 위해서는 여러개의 실험이 동시에 진행되더라도 각 실험들이 서로에게 영향을 미치지 않고 <strong>실험 간 독립성이 보장되어야만 하는데</strong>, 결국 이는 실험에 참여하는 유저들을 임의로 나누어 놓은 <strong>“버켓”</strong>의 퀄리티와 직접적인 연관이 있다.</p>

<p>이러한 맥락에서 <strong>“parallel experiment platform”</strong>이란, 동일한 유저들(모수)을 여러 실험들에서 중복해 사용할 수 있도록 설계된 실험 플랫폼을 의미한다. 만약 실험에 가용될 수 있는 전체 유저 수가 10만명이며 동시에 두개의 실험을 진행한다고 할 때, parallel experiment platform에서는 매 실험마다 10만명의 표본을 전부 활용할 수 있다.</p>

<p>한편, 이와는 반대로 <strong>“non-parallel experiment platform”</strong>에서는 동시에 진행되는 두개의 실험에 대해 각각 5만명씩의 유저가 할당된다. 즉, parallel experiment platform에 비해 각 실험마다 약 절반 정도의 표본 크기를 손해보게되는 것이다.</p>

<p>각각에 대해서 좀 더 구체적으로 살펴보자.</p>

<p> </p>

<h3 id="non-parallel-experiment-platform">Non-parallel Experiment Platform</h3>

<p>설명의 편의를 위해, 총 $N=10000$ 의 모집단 크기와 대조군 시험군 각각에 절반의 샘플이 할당되는 (i.e. 50/50 split) 서로 다른 두개의 실험 $P_1, P_2$ 가 있다고 가정하겠다. 만약 해당 실험에서 모든 표본을 사용한다고 할 때, non-parallel experiment platform에서 각 실험 집단별 버켓 $B$ 의 크기는 다음과 같다.</p>

<p> </p>

<center>

$$
\begin{aligned}
|B_{P_1, c}| &amp;= |B_{P_1, t}| = |B_{P_2, c}| =|B_{P_2, t}| =2500 \\[10pt]
&amp;c: \text{control} \\
&amp;t: \text{treatment}
\end{aligned}
$$

</center>

<p> </p>

<p>즉 실험이 두개이므로 각 실험에 5천명씩의 표본이 할당되었으며, 각 실험 내에서 또 다시 대조군과 시험군의 두 그룹으로 나뉘기 때문에 최종적으로 각 버켓에는 2500명의 유저가 배정되는 것이다.</p>

<p>이러한 실험 플랫폼 디자인의 장단점은 다음과 같다.</p>

<p><strong>&lt;장점&gt;</strong></p>

<ul>
  <li>쉽고 간단하다.</li>
  <li>모든 실험은 각각 독립적인 버켓(샘플)을 바탕으로 수행되기 때문에, 각 실험 간에 <strong>교호 작용 (interaction) 이 발생하지 않는다.</strong></li>
</ul>

<p><strong>&lt;단점&gt;</strong></p>

<ul>
  <li>버켓별 <strong>표본의 크기가 줄어든다</strong> (실험의 개수에 따라서 각 버켓에 할당되는 표본수가 linear하게 감소).</li>
  <li>버켓의 개수가 충분하지 않을 경우, <strong>동시에 여러개의 실험을 진행할 수 없다</strong>.</li>
</ul>

<p> </p>

<h3 id="parallel-experiment-platform">Parallel Experiment Platform</h3>

<p>한편, 이러한 단점을 보완하기 위해서 <strong>전체 모집단(population)이 여러 실험에 동시에 활용되도록 실험 플랫폼을 설계할 수 있다</strong>. 하루에도 수백, 수천개의 A/B Test가 동시에 진행되는 구글과 마이크로소프트, 페이스북 등의 플랫폼들이 그 예시라고 할 수 있다.</p>

<p>앞서 살펴본 예시에서, parallel experiment platform의 경우 각 실험 집단별 버켓 $B$ 의 크기는 다음과 같다.</p>

<p> </p>

<center>

$$
\begin{aligned}
|B_{P_1, c}| &amp;= |B_{P_1, t}| = |B_{P_2, c}| =|B_{P_2, t}| = 5000 \\[10pt]
&amp;c: \text{control} \\
&amp;t: \text{treatment}
\end{aligned}
$$

</center>

<p> </p>

<p>즉, non-parallel design에 비해 각 버켓에 할당되는 표본 수가 두배로 늘어났으며, 늘어난 표본 크기에 대응해서 실험의 검정력이 역시 증가할 것임을 알 수 있다.</p>

<p>하지만 위와 같은 parallel experiment platform에서는 한 가지 중요한 이슈가 발생하는데, 이는 바로 동일한 유저들이 서로 다른 실험에 동시에 참여하기 때문에 <strong>실험 간 교호 작용 (interaction effect) 이 발생할 수 있다는 점이다</strong>.</p>

<p>만약 이처럼 각 실험에서 사용되는 표본(버켓)들이 서로 독립이 아닐 경우 이는 통계적으로 bias를 발생시켜 실험의 결과를 왜곡시킬 우려가 있다. 가령, 만약 첫번째 실험에서 대조군에 배정된 유저들이 두번째 실험에서도 대조군에 배정될 가능성이 높아진다면 A/B Test 필수 요소인 무작위 배정의 원칙이 깨지게 된다. 따라서 parallel experiment platform에서는 진행되는 실험들의 독립성이 보장될 수 있도록 각별한 주의가 필요하다.</p>

<p> </p>

<hr />

<h1 id="2-independent-experiments">2. Independent Experiments</h1>

<p>그렇다면 구체적으로 어떻게 하면 각 실험의 독립성을 보장하면서 유저들을 버켓에 무작위 배정할 수 있을지를 알아보기에 앞서, 각 실험이 서로 <strong>“독립”</strong>이라는 것의 의미에 대해 잠시 짚고 넘어가도록 하자. 좀 더 자세한 설명은 해당 <a href="">포스트</a>를 참고하라.</p>

<p>실험이 독립적이라는 것은, 한마디로 <strong>특정한 실험의 결과가 다른 실험에 영향을 미치지 않는 것</strong>을 의미한다. 설명의 편의를 위해 다음의 상황을 가정하겠다.</p>

<ul>
  <li>첫번째 실험 <strong>$P_1$ 에서는 기대수익이 $A$ 만큼 증가</strong>하고, 두번째 실험 <strong>$P_2$ 에서는 기대수익이 $B$ 만큼 증가</strong>한다.</li>
  <li>실험 <strong>$P_1$과 $P_2$는 서로 독립이다</strong>.</li>
</ul>

<p>위와 같은 상황에서 실험 $P_1, P_2$에 대해, 버켓의 가능한 모든 조합별 기대수익의 증가량은 다음과 같다:</p>

<center>
  <img src="/images/abtest/52.png" width="400" height="400" /> 
 <br />
 <em><span style="color:grey"></span></em>
</center>

<p> </p>

<p>위 표를 바탕으로, 첫번째 실험 $P_1$의 관점에서 기대수익의 증가량 (effect size) 은 $2A + B - B = 2A$로 두번째 실험 $P_2$의 효과 $B$에 의존하지 않는다는 것을 확인할 수 있다 ($P_2$에 대해서도 마찬가지). 따라서 우리는 위 실험에서는 $P_1, P_2$가 서로 독립이라고 결론내릴 수 있는 것이다.</p>

<p>한편, 이와는 반대로 만약 $P_1$의 effect size가 $B$를 포함되게 된다면, 우리는 두 실험간에 <strong>교호 작용 (interaction effect)</strong> 이 있다고 표현한다. 즉, 첫번째 실험에서의 변경점이 두번째 실험의 변경점으로 인한 효과의 영향을 받아 증가하거나 감소하는 상황을 의미하는 것이다.</p>

<p> </p>

<h3 id="example-simulation-study">Example: Simulation Study</h3>

<p>그렇다면 실제로 각 실험이 <strong>독립</strong>인 경우, 여러개의 실험이 동시에 진행되더라도 통계적으로 bias가 발생하지 않는다는 점을 시뮬레이션 스터디를 바탕으로 파악해보도록 하겠다. 구체적인 내용은 해당 <a href="https://bytepawn.com/running-multiple-ab-tests-in-parallel.html">포스트</a>를 참고했으며, 여기서는 간단하게 <strong>두개의 실험이 동시에 진행되는 경우</strong>에 대한 결과를 살펴볼 예정이다.</p>

<p>시뮬레이션 데이터는 $i$ 번째 실험에서의 유저들의 체류시간 $X_i$ 를 지수 분포로부터 샘플링 했으며, baseline effect size는 대조군과 시험군에 각각에 대해 1과 2로 설정되었다. 또한 이 상황에서 특정한 유저가 treatment를 적용받을 경우 지수 분포의 모수가 1만큼 증가하도록 의도되었다.</p>

<p> </p>

<center>

$$
\begin{aligned}
X_{i, c} &amp;\sim \text{Exp}(1) \\[10pt]
X_{i, t} &amp;\sim \text{Exp}(2), \quad i \in \{P_1, P_2\} \\[10pt]
\end{aligned}
$$

</center>

<p> </p>

<p>위와 같은 세팅에서 <strong>10,000 명의 표본</strong>에 대해 서로 다른 두개의 실험 $P_1, P_2$을 동시에 진행하는 경우, 개별적인 유저의 관점에서 배정받을 수 있는 모든 버켓(서로 다른 모수를 갖는 지수분포)의 종류는 다음과 같다:</p>

<center>
  <img src="/images/abtest/53.png" width="800" height="600" /> 
 <br />
 <em><span style="color:grey"></span></em>
</center>

<p> </p>

<p>이처럼 실험의 결과로 인해 발생될 수 있는 모수의 종류는 총 <strong>4가지</strong>이며 각 실험간 교호 작용은 존재하지 않는다고 가정되었다. 또한 결과의 시각화를 위해 위와 같은 4개의 모수를 서로 다른 <strong>색깔</strong>로 인코딩 했다.</p>

<p>이제 총 10,000명의 개별적인 표본들에 대해서, 50/50 random split을 바탕으로 수행된 독립적인 두 개의 실험에 대한 결과 (모수의 크기 = 색깔) 를 100x100 이미지로 표현해보자. 이 때 각각의 1x1 픽셀은 개별적인 한명의 유저를 의미하게 된다.</p>

<center>
  <img src="/images/abtest/54.png" width="500" height="350" /> 
 <br />
 <em><span style="color:grey"></span></em>
</center>

<p> </p>

<p>왼쪽의 그림은 각 표본들에 대한 실제 모수 (1,2,3,4 중 한개) 를 의미하며, 오른쪽 그림은 해당 모수를 갖는 지수분포로 부터 샘플링된 값을 의미한다.</p>

<p>이 때 우리가 살펴봐야할 것은 위 그림들에서 <strong>모든 색깔이 랜덤하게 분포되어 있는지의 여부</strong>인데, 위 그림은 살짝 보기가 불편하므로 두개의 모수 쌍 (1,2 // 3,4) 을 기준으로 재정렬해서 다음과 같이 픽셀들을 재정렬했다.</p>

<center>
  <img src="/images/abtest/55.png" width="500" height="350" /> 
 <br />
 <em><span style="color:grey"></span></em>
</center>

<p> </p>

<p>한눈에 봐도 서로 다른 두개의 실험에서 대조군과 시험군이 uniform하게 분포되어 있는 것을 확인할 수 있다. 이는 유저들이 두개의 실험에 동시에 참여했음에도 불구하고, 유저들에 대한 버켓, 즉 각 실험에서의 대조군과 시험군이 모두 독립인 것을 의미한다. 따라서 결론적으로 <strong>버켓들의 독립성이 보장되기만 한다면 서로 다른 실험 $P_1$과 $P_2$를 동시에 진행하더라도 무작위 배정의 측면에서 아무런 문제가 발생하지 않음을 확인할 수 있다</strong>.</p>

<p> </p>

<hr />

<h1 id="3-dependent-experiments">3. Dependent Experiments</h1>

<p>한편, 위와는 다르게 만약 각 실험이 서로 독립이 <strong>아닐</strong> 경우, 즉 실험 간 <strong>교호 작용</strong>이 있는 경우와 관련한 사례들을 간략하게 살펴보도록 하겠다.</p>

<p>우선 가장 간단하게 생각해볼 수 있는 가능성은, 두 실험에서 <strong>테스트하고자 하는 기능 간에 서로 밀접한 연관성</strong>이 있어서 시너지 효과를 내는 경우가 있을 수 있다. 예를 들어, 실험 1에서는 특정 웹사이트의 <strong>“폰트 크기”</strong>를, 실험 2에서는 <strong>“폰트 색깔”</strong>을 실험하고 있다고 해보자. 이 경우 실험을 진행하는 대상이 “동일한 웹사이트에 대한 폰트”라는 점에서 자연스레 교호작용이 발생할 것이라고 유추해볼 수 있다.</p>

<p><strong>&gt;&gt; e.g. “폰트의 크기가 커짐” + “폰트 색깔이 빨간색”  → 더 낮은 전환율 (아마 눈이 아파서..?)</strong></p>

<p> </p>

<p>한편, 또 하나의 가능성은 각 실험에 사용되는 <strong>“버켓”들이 서로 독립적이지 않은 경우이다</strong>. 버켓들이 서로 균등하지 않다는 것은 <strong>무작위 배정이 제대로 수행되지 않았음을 의미하는데</strong>, 이는 온라인 A/B 테스트에서 bias를 발생시키는 가장 흔한 원인 중 하나이다. 또한 이는 디버깅이 상당히 까다롭기 때문에 A/A Test, SRM (Sample Ratio Mismatch) 등을 통해서 문제가 발생했다는 사실은 알 수 있더라도, 구체적으로 시스템 상 어느 부분이 원인인지를 밝혀내는 것은 상당한 인내심을 필요로 한다.</p>

<p>이와 관련해서 온라인 실험 플랫폼에서 무작위 배정, 즉 버켓 할당 (bucket assignment) 이 수행되는 과정을 구체적으로 살펴보며 어떻게 하면 parallel experiment platform을 설계할 수 있을지에 대해 알아보도록 하겠다.</p>

<p> </p>

<hr />

<h1 id="4-randomization-algorithms">4. Randomization Algorithms</h1>

<p><a href="https://ai.stanford.edu/~ronnyk/2007GuideControlledExperiments.pdf">Microsoft</a>는 성공적인 실험 플랫폼을 위해서 randomization algorithm이 만족해야할 기본적인 성질들을 다음과 같이 정의하고 있다.</p>

<ol>
  <li>Assignment of variants to members happens according to the desired split. There should be no bias toward any particular variant (i.e. <strong>no sample size ratio mismatch</strong>).</li>
  <li>Variant assignment of a single user is <strong>deterministic</strong>; the user should be assigned to the same variant on each successive visit to the site.</li>
  <li>When multiple experiments are run concurrently, there must be <strong>no correlation between experiments</strong>. A user’s assignment to a variant in one experiment must have no effect on the probability of being assigned to a variant in any other experiment.</li>
  <li>The algorithm should support <strong>monotonic ramp-up</strong>, meaning that the percentage of users who see a Treatment can be slowly increased without changing the assignments of users who were already previously assigned to that Treatment.</li>
</ol>

<p> </p>

<p>이중에서도 특히나 세번째 성질인 <strong>실험의 독립성</strong>을 보장하는 것이 상당히 중요하면서 까다로운 작업이다.</p>

<p>실제로 (곧 살펴볼) 대부분의 해시 함수들을 이용한 randomization은 [1], [2], [4] 의 성질은 잘 만족하더라도 [3]의 성질을 만족하지 못하는 경우가 많다는 것이 연구되었습니다 <a href="https://medium.com/@thisisflea/a-good-hash-is-hard-to-find-6edbbf6a78b0">(참고)</a>.</p>

<p>그렇다면 구체적으로 어떤 방법들이 있는지를 알아보겠습니다.</p>

<p> </p>

<hr />

<p>&lt;/center&gt;</p>

<p> </p>

<hr />

<h1 id="reference">Reference</h1>

<ul>
  <li>Casella, G., &amp; Berger, R. L. (2002). <em>Statistical inference.</em> 2nd ed. Australia ; Pacific Grove, CA: Thomson Learning.</li>
</ul>

:ET