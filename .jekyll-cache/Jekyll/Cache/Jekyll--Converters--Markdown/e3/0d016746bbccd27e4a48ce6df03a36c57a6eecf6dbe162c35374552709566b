I"M@<p>해당 포스트에서는 A/B Test에서 아웃라이어의 처리가 필요한 이유와 이를 위한 몇가지 방법론들을 살펴볼 예정이다.</p>

<p> </p>

<hr />

<h1 id="1-outliers-in-ab-test">1. Outliers in A/B Test</h1>

<p>본격적인 내용을 살펴보기에 앞서, 아웃라이어의 의미에 대해서 간략하게 생각해보도록 하자.</p>

<p>통계학에서 <strong>“아웃라이어”</strong>란, 대다수의 <strong>“정상적인”</strong> 데이터와 그 성질이 사뭇 다른 데이터를 의미한다. 따라서 컴퓨터 과학, 머신러닝, 통계학의 범주를 아우르는 <strong>아웃라이어 탐지 과제</strong>는 주어진 데이터로부터 정상적인 패턴과 비정상적인 패턴을 구분하는 것이 주된 관심사라고 할 수 있다.</p>

<p>한편, 아웃라이어를 정의하는 것은 그리 간단하지만은 않다. 가령, 대한민국 남성의 평균 키가 약 170cm 중반이라는 점을 감안할 때, 일반적으로 <strong>키가</strong> <strong>200cm가 넘어가는 남성</strong>들은 아웃라이어라고 판단할 수 있을 것이다. 한편, 만약 우리의 관심사가 <strong>농구 선수</strong>들의 키라고 한다면 이 때는 키가 200cm가 넘어가는 남성들을 아웃라이어라고 판단하기는 다소 어려울 수 있다.</p>

<p>이처럼 아웃라이어 탐지는 주어진 데이터의 맥락을 고려해야 한다는 특징이 있다. 이러한 맥락에서 아웃라이어는 크게 <strong>“절대적 아웃라이어”</strong>와 <strong>“상대적 아웃라이어”</strong>의 범주로 구분될 수 있다.</p>

<p>자 이제 A/B Test의 맥락에서 아웃라이어 처리의 목적에 대해서 살펴보자. A/B Test는 대조군과 시험군 간의 <strong>“평균적인 경향성”</strong>을 파악하기 위해 수행된다. 즉, 다른 모든 조건이 동일할 때 특정한 기능을 적용 받은 사람들이 그렇지 않은 사람들에 비해 어떠한 차이가 있는지를 파악하는 것이 일차적인 목표라고 할 수 있다. 이러한 맥락에서 A/B Test에서의 아웃라이어 탐지는 그 성격상 “상대적 아웃라이어”를 찾고, 해당 값들을 적절히 처리하기 위한 목적으로 수행된다.</p>

<p>그렇다면 A/B Test에서 아웃라이어를 처리하는 것이 왜 중요할까? 설명의 편의를 위해 가장 일반적인 연속형 지표의 모평균에 대한 이표본 t검정 (two sample t-test) 를 바탕으로 논의를 이어가겠다. 이 때, 실험에 사용되는 검정통계량은 다음과 같다.</p>

<center>

$$
t_{df} = \frac{(\bar X_1 - \bar X_2) - (\mu_1 - \mu_2)}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}
$$

</center>

<p> </p>

<p>이를 바탕으로, 통계적 가설 검정은 해당 검정통계량이 기각역보다 클 경우 귀무 가설을 기각하고 두 그룹간 차이가 통계적으로 유의미하다는 결론을 내리는 방식으로 진행된다. 다시 말해, 실험의 유의성을 주장하기 위해서 우리는 (일반적으로) <strong>더 큰 검정통계량을 값을 얻고자 하는 것이다</strong>.</p>

<p>이러한 맥락에서 검정통계량 $t_{df}$ 를 좀 더 구체적으로 뜯어보도록 하자. 여기서 중요한 것은 해당 식의 <strong>분모</strong>인데, 이는 대조군과 시험군의 표본 분산 $s_1^2, s_2^2$과 샘플 사이즈 $n_1, n_2$로 구성되어 있다는 점을 알 수 있다. 일반적인 A/B Test에서 수집될 샘플 사이즈는 실험의 기획 단계에서 정해지기 때문에 $n_1$과 $n_2$는 우리의 주된 관심사는 아니다.</p>

<p>한편, 각 집단별 표본 분산 $s_1^2, s_2^2$는 수집된 데이터에 영향을 받게 되는데, 구체적으로 <strong>$s_1^2, s_2^2$의 값이 작아지면 작아질 수록 전체적인 검정통계량 $t_{df}$의 값이 커지게 된다</strong>. 그렇기 때문에 수집된 데이터의 분산을 줄이는 것은 우리의 분명한 관심사가 되는 것이다.</p>

<p>그렇다면 어떻게 데이터의 분산을 줄일 수 있을까? 분산은 데이터의 변동성을 측정하는 지표이다. 그리고 <strong>아웃라이어의 존재는 종종 데이터의 분포를 불안정하게 만들어 분산을 증가시킨다 (inflation of variance)</strong>. 따라서 적절히 아웃라이어를 제거해주는 작업은 실험의 비용 측면에서 상당히 중요한 과제라고 할 수 있다.</p>

<p>이 밖에도 모평균에 대한 검정에서 아웃라이어를 처리하는 것은 정규 근사의 측면에서도 의미가 있다. 일반적으로 온라인 A/B Test에서 수집되는 웹 데이터는 양의 왜도 (skewness) 가 상당히 크다는 점에서, 극단적인 아웃라이어를 제거하는 것을 통해 중심 극한 정리가 작동하기 위한 표본 평균의 정규 근사 정도를 보장할 수 있다.</p>

<p>한편, 그럼에도 불구하고 아웃라이어를 어떠한 방식으로든 처리한다는 것은 수집된 데이터에 사후적인 변형을 가하는 점이라는 사실을 항상 유념해야 한다. 잘못된 아웃라이어 처리는 실험의 결과를 왜곡할 수 있기 때문에 아웃라이어 처리 로직에 대한 충분한 정당화가 가능해야 할 것이다. 이러한 맥락에서 온라인 A/B Test에서 흔히 활용되는 몇가지 아웃라이어 처리 방법론들에 대해 살펴보도록 하겠다.</p>

<p> </p>

<p> </p>

<hr />

<h1 id="2-strategies">2. Strategies</h1>

<p>일반적인 아웃라이어 탐지 테스크와는 다르게, 온라인 A/B Test에서의 아웃라이어 처리의 특징은 거의 대부분의 경우 <strong>일차원의 데이터를 다룬다는 점이다 (시험군 vs 대조군)</strong>. 그렇기 때문에 학계에서 연구되는 (주로 고차원 데이터에서의) 복잡한 아웃라이어 탐지 방법론과는 다르게 비교적 간단한 통계 방법론도 상당히 효과적으로 활용될 여지가 있다.</p>

<p>이러한 맥락에서 온라인 A/B Test에서 활용될 수 있는 아웃라이어 처리 방법론 몇가지를 간략히 정리해보도록 하겠다.</p>

<p> </p>

<h3 id="quantile-winsorization">Quantile Winsorization</h3>

<p>통계학에서 <strong>“winsorizing”</strong>, 또는 <strong>“capping”</strong> 이란, 주어진 데이터에서 <strong>일정한 기준점을 넘어가는 값을 특정한 값으로 대체하는 것이다</strong>. 이와 관련해 “<strong>quantile winsorization</strong>“은 해당 기준점을 데이터에서의 분위 수로 지정해 아웃라이어를 처리한다.</p>

<p>해당 방법은 개념적으로도, 구현상으로도 상당히 간단하기 때문에 쉽게 적용할 수 있다는 장점이 있으나, 문제는 해당 방법을 적용할 경우 데이터의 형태를 고려하지 않은채 항상 일정한 %의 데이터가 아웃라이어로 간주되어 대체된다는 점이다. 가령, 아웃라이어가 없는 깨끗한 데이터의 경우 정상적인 데이터가 잘려나가는 이슈가 발생할 수 있다. 이처럼 데이터의 분포 형태를 고려하지 않은채 아웃라이어를 처리하는 방법은 안전성의 측면에서 다소 우려가 있을 수 있다.</p>

<p> </p>

<center>
  <img src="/images/abtest/41.png" width="500" height="300" /> 
 <br />
 <em><span style="color:grey">5% quantile winsorization 예시</span></em>
</center>

<p> </p>

<h3 id="3-sigma-rule">3-$\sigma$ Rule</h3>

<p>3-$\sigma$ rule 방법은 정규분포의 성질을 바탕으로 아웃라이어를 정의한다.</p>

<p>정규 분포의 누적 확률 밀도 함수 (i.e. cdf) 를 바탕으로 할 때, 우리는 다음과 같이 평균 $\mu$ 를 기준으로 표준 편차 $\sigma$의 값에 따라 $[\mu - 3\sigma , \mu + 3\sigma]$ 의 범위 안에 약 99.7%의 확률 밀도가 존재하는 것을 이론적으로 알고 있다.</p>

<p> </p>

<center>
  <img src="/images/abtest/42.png" width="500" height="300" /> 
 <br />
 <em><span style="color:grey"></span></em>
</center>

<p> </p>

<p>따라서 정규분포를 따르는 종 모양의 데이터에 대해 $\mu \pm 3\sigma$ 의 기준점을 세울 경우, 해당 범위에 포함되지 않는 약 0.3%의 데이터를 우리는 자연스레 아웃라이어로 간주할 수 있다.</p>

<p>이처럼 3-$\sigma$ rule은 <strong>경험 법칙 (rule of thumb)</strong>에 의거한 방법인데, 그 이론적 정당성은 모평균에 대한 검정에서 충분한 샘플 사이즈가 보장될 경우 중심극한정리가 작용한다는 것에 기반한다. 그렇기 때문에 많은 실험 플랫폼에서 해당 방법을 아웃라이어 처리에 활용하고 있다. (참고 - <a href="https://support.optimizely.com/hc/en-us/articles/4410289414413-How-Optimizely-Handles-Outliers">Optimizely</a>)</p>

<p>한편, 해당 방법 역시 완벽한 것은 아니다. 비록 구현이 간단하다는 장점이 있으나, 대부분의 온라인 웹 데이터의 경우 앞서 언급한 것처럼 양의 왜도가 상당하기 때문에 데이터의 오리지널 분포가 완벽한 종모양을 따르는 경우는 거의 없다. 따라서 실제로 3-$\sigma$ rule이 어느 정도 유효하게 작용하기 위해서는 수집된 데이터에 대한 로그 변환 또는 <a href="https://towardsdatascience.com/box-cox-transformation-explained-51d745e34203">Box-cox 변환</a> 등의 추가적인 밑작업이 필요할 수 있다.</p>

<p> </p>

<h3 id="cuped-microsoft">CUPED (Microsoft)</h3>

<p>앞서 살펴본 두 방법과는 다르게, 2013년에 마이크로소프트에서 발표한 <a href="https://exp-platform.com/Documents/2013-02-CUPED-ImprovingSensitivityOfControlledExperiments.pdf">CUPED (Controlled-experiment Using Pre-Existing Data)</a> 라는 방법론은 좀 더 까다로운 통계적 디테일을 포함하고 있다.</p>

<p>해당 방법론의 핵심적인 아이디어는 통계학의 <strong><em>control variable</em></strong> 을 응용한 것으로, 특정한 실험이 진행되기 이전에 갖고 있는 historical data를 공변량으로 활용해서 지표의 분산을 보정해주겠다는 내용이다. 이렇게만 말하면 무슨 말인지 이해하기가 어렵기 때문에 구체적인 예시를 바탕으로 살펴보도록 하자.</p>

<p>여기서는 설명의 편의를 위해, 특정한 유저 3명이 있다고 가정하도록 하겠다. 우리의 관심 지표는 각 유저별 <strong>평균 매출액</strong>이다. 직관적으로, 우리는 각 유저별로 일정한 <strong>“소비 성향”</strong>이 있을 것이라고 생각해볼 수 있다. 즉, 한마디로 기존에 매출액이 높았던 유저들은 앞으로도 매출액이 높을 것이며, 반대로 기존에도 거의 구매를 하지 않던 유저들은 앞으로도 별로 구매를 하지 않을 것이라는 아이디어이다. 물론 이와 같은 유저들의 행동 패턴은 시간이 지남에 따라 바뀔 수 있으나 전체적인 모집단의 수준에서는 어느 정도 일정한 경향성이 유지될 것이다. 이러한 맥락에서 <strong><em>“control variable”</em> 이란 각 유저별 과거 시점에서 집계된 데이터가 된다 (pre-experiment)</strong>.</p>

<center>
  <img src="/images/abtest/43.png" width="500" height="300" /> 
 <br />
 <em><span style="color:grey"></span></em>
</center>

<p> </p>

<p>이처럼 가설 검정에 대한 통계 모형에 control variable을 포함시키게 될 경우, 각 유저별 과거 시점과 현 시점의 중복된 정보량이 어느 정도 상쇄되고 오로지 관심 변수 (treatment) 의 순수한 효과만이 남게 될 것이다. 그리고 이렇게 불필요한 정보가 통계적으로 보정되었기 때문에 결과적으로 지표의 변동성 (i.e. 분산) 이 감소한다는 사실은 그리 어렵지 않게 받아들일 수 있다.</p>

<p> </p>

<p>이렇게 CUPED 방법론을 직관적인 측면에서 살펴보았다면, 다음으로는 통계적으로 CUPED이 어떻게 정의되는지를 살펴보자.</p>

<p>과거 시점의 control variable를 편의상 $X$ 로 정의할 때, 대조군 $Y_C$ 와 시험군 $Y_T$ 각각에 대한 현 시점에서의 평균 $\bar Y_C, \bar Y_T$ 를 구하기 위해 CUPED는 다음과 같은 estimator (추정량) 를 활용한다.</p>

<center>

$$
\bar Y_{i}^* = \bar Y_i - \theta^*\big(\bar X_i - \mathbb{E}(X)\big), \quad (i\in\{C,T\})
$$

</center>

<p> </p>

<p>위 estimator을 구체적으로 뜯어보자. 우선 $\bar Y_i$는 현재 진행된 실험에서 수집된 데이터의 표본 평균이다 (노테이션의 편의상 유저에 대한 인덱스는 생략했다). 이 때 CUPED estimator $\bar Y_i^*$ 는 $\bar Y_i$ 로 부터 무언가를 뺀 값으로 정의되는 것을 확인할 수 있다. 그리고 바로 이 “무언가”가 바로 앞서 언급한 control variable, 즉 과거 시점의 데이터가 되는 것이다. 이제 남은 것은 공변량의 앞에 붙어 있는 $\theta^*$ 인데, 이는 어떠한 상수로써 분산을 최소화시킬 수 있는 값으로 설정된다 (잠시 뒤 다시 살펴보겠다).</p>

<p>한편, 이렇게 새롭게 정의된 estimator는 당연하게도 통계적으로 타당해야만 한다. 이를 살펴보기 위해서 해당 estimator에 평균을 취하면 무슨일이 일어나는지를 살펴보자.</p>

<center>

$$
\begin{aligned}
\mathbb{E}\big[ \bar Y_i^* \big] &amp;= \mathbb{E}\Big[\bar Y_i - \theta^*\big(\bar X_i - \mathbb{E}(X)\big) \Big] \\[10pt]

&amp;=\mathbb{E}[\bar Y_i] - \theta^*\mathbb{E}\big[\bar X_i - \mathbb{E}[X]\big] \\[10pt]

&amp;=\mathbb{E}[\bar Y_i] - \theta^* \big( \mathbb{E}[\bar X_i] - \mathbb{E}[X] \big) \\[10pt]

&amp;= E[\bar Y_i]

\end{aligned}
$$

</center>

<p> </p>

<p>즉, CUPED estimator는 <strong>불편추정량 (unbiased estimator)</strong> 임을 확인할 수 있다.</p>

<p>다음으로는 어떻게 하면 분산을 최대로 감소시킬 수 있을지와 관련해서, 가장 최적의 $\theta$ 값을 유도해보도록 하자.</p>

<p> </p>

<center>

$$
\begin{aligned}
Var\Big(\bar Y_i - \theta\big(\bar X_i - \mathbb{E}(X)\big) \Big) &amp;= Var\big(\bar Y_i - \theta \bar X_i \big) \\[10pt]
&amp;= \frac{1}{n} Var(Y_i - \theta X_i) \\[10pt]

&amp;= \frac{1}{n}\Big( Var(Y_i) + \theta^2 Var(X_i) - 2\theta\;\text{Cov}(Y_i, X_i) \Big) \\[10pt]

&amp;= C_1\Big( \theta - \frac{\text{Cov}(Y_i, X_i)}{Var(X_i)} \Big)^2 + C_2 ,\quad (C_1, C_2 \text{ is some constant terms}) \\[10pt]
&amp;\therefore \text{minimized when }\;\theta = \frac{\text{Cov}(Y_i, X_i)}{Var(X_i)} \;\text{ by convexity.}

\end{aligned}
$$

</center>

<p> </p>

<p>이는 CUPED estimator에 대한 분산을 유도하는 과정에서 이를 $\theta$ 에 대한 2차 함수로 생각한 다음, 해당 함수를 최소화하는 극값을 찾은 것이다. 그렇다면 이어서 이렇게 찾은 $\theta^*$ 값을 실제로 CUPED estimator에 대입한 다음, 분산을 계산해보도록 하자.</p>

<p> </p>

<center>

$$
\begin{aligned}
Var\Big(\bar Y_i - \theta\big(\bar X_i - \mathbb{E}(X)\big) \Big) &amp;= 
Var\Big(\bar Y_i - \frac{\text{Cov}(Y_i, X_i)}{Var(X_i)} \big(\bar X_i - \mathbb{E}(X)\big) \Big) \\[10pt]

&amp;= Var\Big(\bar Y_i - \frac{\text{Cov}(Y_i, X_i)}{Var(X_i)} \bar X_i \Big) \\[10pt]

&amp;= Var(\bar Y_i) - \frac{\text{Cov}(Y_i, X_i)^2}{Var(\bar X_i)}  \\[10pt]

\end{aligned}
$$

</center>

<hr />

<p><img src="/Users/kakao/Library/Application Support/typora-user-images/스크린샷 2022-07-18 오후 10.08.11.png" alt="스크린샷 2022-07-18 오후 10.08.11" /></p>

<p><img src="/Users/kakao/Library/Application Support/typora-user-images/스크린샷 2022-07-18 오후 9.36.01.png" alt="스크린샷 2022-07-18 오후 9.36.01" /></p>

<p> </p>

<p> </p>

<h3 id="otpsm-yahoo">OTPSM (Yahoo)</h3>

<p> </p>

<p> </p>

<hr />

<p>&lt;/center&gt;</p>

<p> </p>

<hr />

<h1 id="reference">Reference</h1>

<ul>
  <li>https://www.dynamicyield.com/lesson/outliers-detection/</li>
  <li>https://towardsdatascience.com/68-95-99-7-the-three-sigma-rule-of-thumb-used-in-power-bi-59cd50b242e2</li>
  <li>https://uxplanet.org/how-to-clean-ab-testing-data-before-analysis-113e6bfeb164</li>
  <li></li>
</ul>

:ET