I"¦<h3 id="previous-posts">Previous Posts</h3>

<p><a href="https://domug.github.io/2020/12/03/Estimation_Multicollinearity/">1. Statistical Estimation and Multicollinearity</a></p>

<p><a href="https://domug.github.io/2020/12/04/Ridge_Lasso/">2. Variable Selection Methods</a></p>

<p><a href="https://domug.github.io/2020/12/05/PCA/">3. Principal Component Analysis</a></p>

<p><a href="https://domug.github.io/2020/12/06/FA/">4. Factor Analysis</a></p>

<p><a href="https://domug.github.io/2020/12/06/CA/">5. Cluster Analysis</a></p>

<hr />

<h1 id="discriminant-analysis-da">Discriminant Analysis (DA)</h1>

<p>As a final topic of this series, we will talk about <strong>discriminant analysis</strong> and what it exactly does.</p>

<p>By now, you would have probably felt that there are lots of different methods regarding statistical dimension reduction and they could be tangled up in your head because they all seem to be doing similar stuffs. To be honest, itâ€™s the reason why Iâ€™ve decided to write blog posts on these issues because I get confused as well. While studying on this topic, what Iâ€™ve found out is that the main focus or goal of each method are slightly different.</p>

<p>To make a long story short, Discriminant Analysis and the two previous methods, PCA and FA, are very similar by their nature. All three methods try to find the <strong>linear combination</strong> of the original variables to re-express the data. Nevertheless even if they share the same concept, the way how they actually implement the linear transformation of variables are all different.</p>

<p>For instance, PCA does not take into account any discrepancies between groups. PCA simply changes our viewpoint of looking at a data and thatâ€™s all. On the other hand, FA and DA tries to extract the commonalities in the original variables by making groups.</p>

<hr />

<p align="center">
	<img width="700" height="500" src="/images/ca/distances.pn" />
</p>

:ET