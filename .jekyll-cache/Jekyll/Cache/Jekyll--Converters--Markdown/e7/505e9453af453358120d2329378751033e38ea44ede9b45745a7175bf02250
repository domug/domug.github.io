I"˜<h3 id="previous-posts">Previous Posts</h3>

<p><a href="https://domug.github.io/2020/12/03/Estimation_Multicollinearity/">1. Statistical Estimation and Multicollinearity</a></p>

<p><a href="https://domug.github.io/2020/12/04/Ridge_Lasso/">2. Variable Selection Methods</a></p>

<p><a href="https://domug.github.io/2020/12/05/PCA/">3. Principal Component Analysis</a></p>

<p><a href="https://domug.github.io/2020/12/06/FA/">4. Factor Analysis</a></p>

<hr />

<h1 id="cluster-analysis-ca">Cluster Analysis (CA)</h1>

<p>In this post, we will be talking about <strong>Cluster Analysis</strong>. Until now we have seen PCA and FA which reduced dimensionality of the original data in terms of its â€œvariablesâ€. Both methods decomposed data matrix by its column vectors, so we were able to find a subset of variables that accounts for enough information of the original data. However, cluster analysis performs dimension reduction on <strong>observations</strong>, that is, by <strong>row vectors</strong>. This difference very important so always keep in mind!</p>

<p>The goal of cluster analysis is to find groups or clusters that can â€œadequatelyâ€ separate and group the observations. Since the word â€œadequatelyâ€ is a little vague in its meaning, we can define the adequacy as follows.</p>
<ul>
  <li><strong>observations inside the same clusters are similar as possible</strong></li>
  <li><strong>observations within different clusters are different as possible</strong></li>
</ul>

<hr />

<h3 id="distance">Distance</h3>

<p>However, even in the above definition we have another ambiguousness. How are we going to measure the similarity and dissimilarity of each observations? Hereâ€™s where we need the concept of <strong>â€œmathematical distanceâ€</strong>. To define distance, we foremost need a â€œmeasureâ€ and there are various definitions of different mathematical measures to define the distance between two objects.</p>

<p align="center">
	<img width="700" height="500" src="/images/ca/distances.png" />
</p>

<p>Above is an example of lists of different distances, but all of them are defined to do one single thing - to measure the <strong>â€œclosenessâ€</strong> of objects. The â€œcloserâ€ the objects are, the more homogeneous or similar they are. Since going into the details of all of the distances above would be tedious and time consuming, letâ€™s focus on some of the key points of distance and move on.</p>

<p>Normally when we think of distance between two things, we are mostly familiar with the <strong>â€œEuclidean Distanceâ€</strong>, which is the most famous and widely used distance measure for calculating <strong>â€œphysical distancesâ€</strong>. â€œPhysical distanceâ€ here literally means the distance of two physical objects. We say Tokyo is around 1,150 km apart from Seoul. This is physical distance.</p>

<p>But itâ€™s important to note that there also exist <strong>â€œpsychological distanceâ€</strong> as well. Like when you are asked, â€œHow close do you think you are with your best friend?â€, you will not likely to answer â€œOh, itâ€™s about 10 metersâ€. In this situation, we need another measurement that can account for our psychological closeness.</p>

<p>Likewise, the measurement of distance can vary according to the goal of our interest and the distance measure to be used for cluster analysis should also be different with respect to the nature of our data. Although most of the data weâ€™ll face is going to be about physical properties, it is worth noticing that we should not blindly rely on the euclidean distance regardless of situation.</p>

<hr />

<h3 id="k-means-clustering">K-Means Clustering</h3>
<p>Anyways, letâ€™s come back to our main topic. Now we are clear that cluster analysis groups observations to make clusters. This process is done in a predefined order and principles, which is formally called as â€œalgorithmâ€. There are lots of clustering algorithms and research is still ongoing.</p>

<p>In this post, we will use an algorithm known as <strong>â€œK-Means Clusteringâ€</strong> which is the most widely implemented clustering methodology. The steps of clustering for K-Means algorithm is the following.</p>

<ol>
  <li>Select number of clusters and distribute the observations accordingly</li>
  <li>Calculate the centroid for each cluster (centroid means the center point)</li>
  <li>For each observation, calculate the within-group distances (= observation - centroid)</li>
  <li>Reallocate observations into the cluster whose centroid is the closest</li>
  <li>If the cluster of any observation has changed, return to step 2 and repeat</li>
</ol>

<p align="center">
	<img width="700" height="500" src="/images/ca/kmeans.gif" />
</p>

<hr />

<hr />

:ET