I"//<p>해당 포스트에서는 통계적 가설 검정에서 등장하는 <strong>“검정력</strong>“의 개념에 대해 리뷰해보도록 하겠다.</p>

<p> </p>

<hr />

<h2 id="1-가장-좋은-통계-검정-방법">1. 가장 좋은 통계 검정 방법?</h2>

<p><strong>통계적 가설 검정</strong>이란 <strong>귀무가설</strong>과 <strong>대립가설</strong>이라는 상반된 두개의 가설을 세운 다음, 관측된 데이터를 이용해서 더 그럴싸 하다고 생각되는 한 개의 가설을 선택하는 절차이다. 그리고 이 과정에서 “더 그럴싸 함”을 판단하기 위한 객관적인 방법이 바로 <strong>통계 검정 방법</strong> 이라고 할 수 있다.</p>

<p>단, 이 과정에서 한가지 주의해야 할 점은 바로 하나의 통계 검정 문제 (ex. A/B Test) 에 대해 <strong>여러가지 통계 검정 방법들이 존재</strong>할 수 있다는 점이다. 가령, 서로 다른 두 그룹 A와 B의 평균을 비교하기 위한 방법에는 그 유명한 이표본 t검정 (two sample t-test) 이외에도 “윌콕슨 순위합 검정 (wilcoxon rank sum test)”, “크루스칼-왈리스 검정 (Kruskall-Wallis Test)” 등의 방법론들이 있다. 이러한 방법론들에 대한 자세한 정리는 해당 <a href="https://domug.github.io/2022/04/18/Statistical_tests/">포스트</a>를 참고하라.</p>

<p>그렇다면 왜 이처럼 하나의 문제에 대해 여러 가지 통계 검정 방법론들이 존재하는 것일까? 비유하자면, 마치 라면을 끓일 때 스프를 먼저 넣는 사람과 면을 먼저 넣는 사람이 있는 것처럼, 특정한 검정 문제에 대해 결론을 도출하는 방법 자체는 매우 다양할 수 있다. 극단적인 예로 “동전을 던져서 앞면이 나오면 A가 더 좋다고 결론 내리고, 뒷면이 나오면 B가 더 좋다고 결론 내리는 방법”이 있다고 해보자. 다소 황당하긴 하지만 이러한 방법 역시 의사 결정에 “일정한 기준”이 있다는 점에서 검정 방법이라고 할 수는 있다. 물론 이런 방법을 사용해서는 올바른 결과를 얻기가 힘들기 때문에 타당한 통계 검정 방법은 아닐 것이다.</p>

<p>이러한 맥락에서 통계 검정 방법의 <strong>“검정력”</strong>이란 여러 검정 방법론들을 비교할 수 있는 객관적인 성능 지표이다. 결론부터 말하자면, 가장 좋은 통계 검정 방법론이란 <strong>1종 오류를 유의수준 이하로 통제하면서, 검정력을 최대화하는 검정 방법</strong> 이다. 이를 이해하기 위해 필요한 통계적 개념들을 하나씩 파악해보도록 하자.</p>

<p> </p>

<hr />

<h2 id="2-1종-오류-vs-2종-오류">2. 1종 오류 vs 2종 오류</h2>

<p>앞서 살펴본 것처럼 통계 검정 방법이란 주어진 데이터를 바탕으로 특정한 가설 검정 문제에 대한 <strong>결론</strong>을 내리기 위한 절차이다. 그리고 당연하게도 이렇게 도출된 결론은 맞을 수도 있고 <strong>틀릴 수도 있다</strong>. 카카오 프렌즈들을 빌려 다음의 두가지 경우를 생각해보자.</p>

<p> </p>

<h4 id="예시-1-귀무가설이-실제로-참인-경우">예시 1: 귀무가설이 실제로 “참”인 경우</h4>

<ul>
  <li>
    <p><strong>귀무가설</strong>: 라이언은 사자이다. (참)</p>
  </li>
  <li>
    <p><strong>대립가설</strong>: 라이언은 사자가 아니다.</p>
  </li>
</ul>

<p>이 경우 우리가 세운 귀무가설은 실제로 참이기 때문에 가설 검정의 결과는 “귀무가설이 맞다” 라는 결론을 내려야한다. 하지만 혹자는 라이언의 귀여운 외형을 보고 곰이라고 <strong>잘못</strong> 판단해 귀무가설을 기각하고 대립가설을 채택할 수도 있다 (실제로 필자는 최근까지 곰인줄 알았다..) 이러한 상황을 통계학에서는 “<strong>1종 오류 (Type I error)</strong>“가 발생했다고 표현한다.</p>

<p> </p>

<h4 id="예시-2-귀무가설이-실제로-거짓인-경우">예시 2: 귀무가설이 실제로 “거짓”인 경우</h4>

<ul>
  <li>
    <p><strong>귀무가설</strong>: 춘식이는 사자이다. (거짓)</p>
  </li>
  <li>
    <p><strong>대립가설</strong>: 춘식이는 사자가 아니다</p>
  </li>
</ul>

<p>예시 1과는 반대로, 이 경우는 실제로는 귀무가설이 거짓인 상황이다. 따라서 가설 검정의 결과로 “귀무가설이 틀리다”는 결론이 도출되어야 한다다. 하지만 위와 마찬가지로 어떤 사람은 춘식이가 라이언과 함께 살기 때문에 아기 사자일 것이라고 잘못 판단해서 귀무가설을 채택할 수도 있다. 이러한 상황을 통계학에서는 “<strong>2종 오류 (Type II error)</strong>“가 발생했다고 표현한다.</p>

<p> </p>

<center>
  <img src="/images/abtest/9.png" width="400" height="300" /> 
 <br />
 <em><span style="color:grey">카카오프렌즈의 공식 소개</span></em>
</center>

<p> </p>

<p>이렇듯 통계 검정 방법은 한번의 실험에 대해 <strong>“귀무가설이 맞다”</strong> 또는 <strong>“귀무가설이 틀리다”</strong> 중 하나의 결론을 제시하기 때문에, 이러한 검정을 여러번 반복했을 때 <strong>평균적으로 얼마나 제대로 된 결론을 내리는지</strong>가 중요한 관심사라고 할 수 있다. 이러한 맥락에서 1종 오류와 2종 오류의 개념은 상당히 중요하다.</p>

<p><strong>1종 오류</strong>: 실제로는 귀무가설이 <strong>맞는데</strong>, 귀무가설이 <strong>틀렸다고</strong> 잘못 결론내릴 확률</p>

<ul>
  <li>e.g. 예시 1에서 라이언이 사자가 아니라고 결론짓는 경우</li>
</ul>

<p><strong>2종 오류</strong>: 실제로는 귀무가설이 <strong>틀렸는데</strong>, 귀무가설이 <strong>맞다고</strong> 잘못 결론내릴 확률</p>

<ul>
  <li>e.g. 예시 2 에서 춘식이가 사자라고 결론짓는 경우</li>
</ul>

<p> </p>

<p>한편, 일반적인 통계적 가설 검정에서 귀무가설은 현재 받아들여지고 있는 주장을 의미하며, 대립가설은 현재의 주장을 반박하는 주장 이라는 점을 저번 포스트에서 살펴본 바 있다. 이를 고려할 때, 귀무가설에 대한 기각은 <strong>현재의 주장을 뒤엎는 것</strong>이기 때문에 일반적으로 <strong>1종 오류가 2종 오류보다 훨씬 더 중요하게 고려된다</strong>.</p>

<p>그렇다면 1종 오류가 2종 오류보다 더 중요하니까 <strong>“1종 오류를 최소화하는 통계 검정 방법이 가장 좋은 것이 아닌가?”</strong> 하는 생각이 들 수 있다.</p>

<p>이를 반박하기 위해, 가령 수집된 데이터를 전혀 고려하지 않은채 “<strong>무조건 귀무가설이 맞다고 결론내리는 검정 방법</strong>“이 있다고 해보자. 이 경우 당연하게도 해당 검정 방법의 <strong>1종 오류</strong>는 정확하게 <strong>0%</strong> 이다. 왜냐하면 모든 결론이 귀무가설이 맞다고 주장하기 때문에, 귀무 가설이 틀렸다고 잘못 주장하는 경우는 없을 것이기 때문이다.</p>

<p>한편, 해당 방법의 치명적인 문제점은 귀무가설이 실제로 틀렸을 때 이를 틀렸다고 할 가능성이 전혀 없다는 점이다. 통계적으로 표현할 때, 이는 <strong>2종 오류</strong>가 <strong>100%</strong>인 상황입니다. 이렇듯 1종 오류와 2종 오류는 한쪽이 커지면 다른쪽은 작아지는 이른바 “<strong>tradeoff relationship</strong>“에 놓여있다 (<a href="https://vwo.com/blog/errors-in-ab-testing/">그림 출처</a>).</p>

<center>
  <img src="/images/abtest/10.png" width="600" height="500" /> 
 <br />
 <em><span style="color:grey">1종 오류와 2종 오류의 관계</span></em>
</center>

<p> </p>

<p>그렇기 때문에 통계학자들은 이러한 두가지 오류 사이에서 적절한 타협점을 찾으려고 노력했고, 그 결과로 일반적으로 더 중요한 <strong>“1종 오류를 일정한 % 까지만 허용하자”</strong> 라는 합의에 다다랐다. 이러한 “1종 오류의 상한선”을 통계학에서는 흔히 그리스 문자 $\alpha$로 표현되는 “<strong>유의 수준 (significance level)</strong>” 이라는 용어로 나타내며, 우리에게 익숙한 0.05라는 기준이 일반적으로 사용된다.</p>

<p>따라서 어떠한 검정 방법이 통계적으로 타당하다고 인정받기 위한 최소한의 조건은 바로 <strong>1종 오류가 유의 수준 이하인 것이 이론적으로 보장되는지의 여부</strong>가 된다. 앞선 예시처럼 단순히 동전던지기를 통해 의사결정을 내리는 방법은 이러한 맥락에서 통계적으로 타당한 검정 방법이 아니라고 할 수 있다.</p>

<p> </p>

<hr />

<h2 id="3-검정력의-정의">3. 검정력의 정의</h2>

<p>앞선 내용에서 통계 검정 방법이란 <strong>1종 오류를 유의수준 이하로 컨트롤</strong>하는 의사 결정 방법이라는 점을 살펴보았다. 따라서 우리가 앞으로 고려할 모든 “타당한” 통계 검정 방법론에서 1종 오류는 더 이상 문제가 되지 않는다. (물론 한 번에 여러개의 가설 검정을 동시에 진행하는 경우 문제가 발생하기도 합니다. 이를 <strong>다중 검정</strong> 이슈라고 하는데, 이는 다음 포스트에서 자세히 말씀드리겠습니다)</p>

<p>이러한 맥락에서, 자연스럽게 다음 관심사는 <strong>“2종 오류는 얼마일 것인가?</strong>” 로 넘어가게 됩니다. 그리고 바로 이 부분에서 해당 포스트의 주제인 <strong>검정력</strong>의 개념이 등장합니다.</p>

<p><strong>검정력 (statistical power)</strong> 이란, 2종 오류의 역 (逆, coverse) 사건에 대한 확률을 의미합니다. 즉, 검정력이란 “<strong>귀무가설이 틀렸을 때</strong><strong>, 실제로 귀무가설이 틀렸다고 올바르게 결론을 내릴 확률</strong>“로 정의되며, 앞선 “예시 2”에서 춘식이가 사자가 아니라고 제대로 판단한 경우가 이에 해당됩니다.</p>

<p>통계학에서 2종 오류는 흔히 그리스 문자 베타(β)로 표현되며, 검정력은 (1-β) 로 정의됩니다. 앞서 말씀드린 것처럼 현재 1종 오류는 유의 수준 이하로 보장된 상황이기 때문에, 따라서 가장 좋은 검정 방법은 <strong>검정력이 최대화되는 방법</strong>입니다.</p>

<p>이렇게 가장 이상적인 검정 방법을 통계학에서는 “<strong>UMP (Uniformly Most Powerful) Test</strong>“라고 정의합니다. 단, 문제는 <strong>UMP Test는 대부분의 가설 검정 문제에 대해 존재하지 않는다는 점</strong>입니다. 좀 더 정확하게 말하면, 존재는 할 수 있으나 수식적으로 계산이 불가능하기 때문에 정의가 안되는 상황입니다. 일례로, “양측검정 문제”에 대해서는 UMP Test가 존재하지 않는다는 것이 일반적으로 알려진 사실입니다.</p>

<p>따라서 실제 가설 검정 절차는 <strong>쉽게 사용할 수 있는</strong> 여러가지 통계 검정 방법론 중에 가장 좋은 방법을 선택하는 방식으로 이루어집니다. 그리고 이 과정에서 “가장 좋은 방법”이란 <strong>1종 오류를 유의 수준 이하로 제한하면서 검정력이 (그나마) 최대가 되는 방법</strong>이 되는 것입니다. 일반적으로 A/B Test가 이표본 t검정을 바탕으로 진행되는 것이 바로 해당 이유 때문이라고 할 수 있습니다.</p>

<p>&lt;/center&gt;</p>

<p> </p>

<hr />

<h1 id="reference">Reference</h1>

<ul>
  <li>Casella, G., &amp; Berger, R. L. (2002). <em>Statistical inference.</em> 2nd ed. Australia ; Pacific Grove, CA: Thomson Learning.</li>
</ul>

:ET