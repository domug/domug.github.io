I"<p>해당 포스트에서는 A/B Test에서 아웃라이어의 처리가 필요한 이유와 이를 위한 몇가지 방법론들을 살펴볼 예정이다.</p>

<p> </p>

<hr />

<h1 id="1-outliers-in-ab-test">1. Outliers in A/B Test</h1>

<p>본격적인 내용을 살펴보기에 앞서, 아웃라이어의 의미에 대해서 간략하게 생각해보도록 하자.</p>

<p>통계학에서 <strong>“아웃라이어”</strong>란, 대다수의 <strong>“정상적인”</strong> 데이터와 그 성질이 사뭇 다른 데이터를 의미한다. 따라서 컴퓨터 과학, 머신러닝, 통계학의 범주를 아우르는 <strong>아웃라이어 탐지 과제</strong>는 주어진 데이터로부터 정상적인 패턴과 비정상적인 패턴을 구분하는 것이 주된 관심사라고 할 수 있다.</p>

<p>한편, 아웃라이어를 정의하는 것은 그리 간단하지만은 않다. 가령, 대한민국 남성의 평균 키가 약 170cm 중반이라는 점을 감안할 때, 일반적으로 <strong>키가</strong> <strong>200cm가 넘어가는 남성</strong>들은 아웃라이어라고 판단할 수 있을 것이다. 한편, 만약 우리의 관심사가 <strong>농구 선수</strong>들의 키라고 한다면 이 때는 키가 200cm가 넘어가는 남성들을 아웃라이어라고 판단하기는 다소 어려울 수 있다.</p>

<p>이처럼 아웃라이어 탐지는 주어진 데이터의 맥락을 고려해야 한다는 특징이 있다. 이러한 맥락에서 아웃라이어는 크게 <strong>“절대적 아웃라이어”</strong>와 <strong>“상대적 아웃라이어”</strong>의 범주로 구분될 수 있다.</p>

<p>자 이제 A/B Test의 맥락에서 아웃라이어 처리의 목적에 대해서 살펴보자. A/B Test는 대조군과 시험군 간의 <strong>“평균적인 경향성”</strong>을 파악하기 위해 수행된다. 즉, 다른 모든 조건이 동일할 때 특정한 기능을 적용 받은 사람들이 그렇지 않은 사람들에 비해 어떠한 차이가 있는지를 파악하는 것이 일차적인 목표라고 할 수 있다. 이러한 맥락에서 A/B Test에서의 아웃라이어 탐지는 그 성격상 “상대적 아웃라이어”를 찾고, 해당 값들을 적절히 처리하기 위한 목적으로 수행된다.</p>

<p>그렇다면 A/B Test에서 아웃라이어를 처리하는 것이 왜 중요할까? 설명의 편의를 위해 가장 일반적인 연속형 지표의 모평균에 대한 이표본 t검정 (two sample t-test) 를 바탕으로 논의를 이어가겠다. 이 때, 실험에 사용되는 검정통계량은 다음과 같다.</p>

<center>

$$
t_{df} = \frac{(\bar X_1 - \bar X_2) - (\mu_1 - \mu_2)}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}
$$

</center>

<p> </p>

<p>이를 바탕으로, 통계적 가설 검정은 해당 검정통계량이 기각역보다 클 경우 귀무 가설을 기각하고 두 그룹간 차이가 통계적으로 유의미하다는 결론을 내리는 방식으로 진행된다. 다시 말해, 실험의 유의성을 주장하기 위해서 우리는 (일반적으로) <strong>더 큰 검정통계량을 값을 얻고자 하는 것이다</strong>.</p>

<p>이러한 맥락에서 검정통계량 $t_{df}$ 를 좀 더 구체적으로 뜯어보도록 하자. 여기서 중요한 것은 해당 식의 <strong>분모</strong>인데, 이는 대조군과 시험군의 표본 분산 $s_1^2, s_2^2$과 샘플 사이즈 $n_1, n_2$로 구성되어 있다는 점을 알 수 있다. 일반적인 A/B Test에서 수집될 샘플 사이즈는 실험의 기획 단계에서 정해지기 때문에 $n_1$과 $n_2$는 우리의 주된 관심사는 아니다.</p>

<p>한편, 각 집단별 표본 분산 $s_1^2, s_2^2$는 수집된 데이터에 영향을 받게 되는데, 구체적으로 <strong>$s_1^2, s_2^2$의 값이 작아지면 작아질 수록 전체적인 검정통계량 $t_{df}$의 값이 커지게 된다</strong>. 그렇기 때문에 수집된 데이터의 분산을 줄이는 것은 우리의 분명한 관심사가 되는 것이다.</p>

<p>그렇다면 어떻게 데이터의 분산을 줄일 수 있을까? 분산은 데이터의 변동성을 측정하는 지표이다. 그리고 <strong>아웃라이어의 존재는 종종 데이터의 분포를 불안정하게 만들어 분산을 증가시킨다 (inflation of variance)</strong>. 따라서 적절히 아웃라이어를 제거해주는 작업은 실험의 비용 측면에서 상당히 중요한 과제라고 할 수 있다.</p>

<p>이 밖에도 모평균에 대한 검정에서 아웃라이어를 처리하는 것은 정규 근사의 측면에서도 의미가 있다. 일반적으로 온라인 A/B Test에서 수집되는 웹 데이터는 양의 왜도 (skewness) 가 상당히 크다는 점에서, 극단적인 아웃라이어를 제거하는 것을 통해 중심 극한 정리가 작동하기 위한 표본 평균의 정규 근사 정도를 보장할 수 있다.</p>

<p>한편, 그럼에도 불구하고 아웃라이어를 어떠한 방식으로든 처리한다는 것은 수집된 데이터에 사후적인 변형을 가하는 점이라는 사실을 항상 유념해야 한다. 잘못된 아웃라이어 처리는 실험의 결과를 왜곡할 수 있기 때문에 아웃라이어 처리 로직에 대한 충분한 정당화가 가능해야 할 것이다. 이러한 맥락에서 온라인 A/B Test에서 흔히 활용되는 몇가지 아웃라이어 처리 방법론들에 대해 살펴보도록 하겠다.</p>

<p> </p>

<p> </p>

<hr />

<h1 id="2-strategies">2. Strategies</h1>

<p>일반적인 아웃라이어 탐지 테스크와는 다르게, 온라인 A/B Test에서의 아웃라이어 처리의 특징은 거의 대부분의 경우 <strong>일차원의 데이터를 다룬다는 점이다</strong>. 그렇기 때문에 학계에서 연구되는 고차원 데이터를 위한 알고리즘을 섣불리 적용하기는 무리가</p>

<p>가 이뤄지고 있는 분야는 상당한 고차원의 데이터에서의</p>

<p> </p>

<hr />

<p>&lt;/center&gt;</p>

<p> </p>

<hr />

<h1 id="reference">Reference</h1>

<ul>
  <li>Casella, G., &amp; Berger, R. L. (2002). <em>Statistical inference.</em> 2nd ed. Australia ; Pacific Grove, CA: Thomson Learning.</li>
</ul>

:ET