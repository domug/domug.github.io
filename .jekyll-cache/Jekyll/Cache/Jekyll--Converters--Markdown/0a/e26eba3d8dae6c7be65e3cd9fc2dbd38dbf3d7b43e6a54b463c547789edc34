I"M <p>This post is an overall summary of Chapter 8 of the textbook <em><a href="http://home.ustc.edu.cn/~zt001062/MaStmaterials/George%20Casella&amp;Roger%20L.Berger--Statistical%20Inference.pdf">Statistical Inference</a></em> by Casella and Berger.</p>

<p><strong>&lt;Table of Contents&gt;</strong></p>

<p><strong>1.1. Sigma Algebra</strong></p>

<p><strong>1.2. Expected Values</strong></p>

<p><strong>1.3. Moment Generating Functions</strong></p>

<p><strong>1.4. Characteristic Functions</strong></p>

<p><strong>1.5. Statistical Independence</strong></p>

<p><strong>1.6. Covariance and Correlation</strong></p>

<p><strong>1.7. Conditional Distributions</strong></p>

<p> </p>

<hr />

<h1 id="5-hypothesis-testing">5. Hypothesis Testing</h1>

<p> </p>

<hr />

<h2 id="51-basics-of-hypothesis-testing">5.1 Basics of Hypothesis Testing</h2>

<p> </p>

<h3 id="511-overview-of-statistical-testing-procedure">5.1.1. Overview of statistical testing procedure</h3>

<p>The typical and most clichéic setting of a statistical hypothesis testing is that from the observations $X_1, \dots, X_n \overset{i.i.d.}{\sim} f_\theta$, we want to test if $\theta = \theta_0$ or not.</p>

<p>A more concrete example is where we have a coin and we are interested in finding out whether the coin is fair (i.e. equal probability of heads and tails) or not. This procedure can formally be expressed as:</p>

<center>

$$
\begin{aligned}
X_1, \dots, X_n &amp;\overset{i.i.d.}{\sim} \text{Bernoulli}(p)\\[10pt]
H_0&amp;: p = \frac{1}{2} \\
H_1&amp;: p \neq \frac{1}{2}
\end{aligned}
$$

</center>

<p>To generalize this problem, we have two sets of parameters $\Theta_0$ and $\Theta_1$ which are <strong>non-overlapping</strong> (i.e. $\Theta_0 \cap \Theta_1 = \emptyset$), and would like to test the hypothesis:</p>

<center>

$$
\begin{aligned}
H_0&amp;: \theta \in \Theta_0 \\[5pt]
H_1&amp;: \theta \in \Theta_1
\end{aligned}
$$

</center>

<p>For the case when $\Theta_0$ is a single point, we call it as a <strong>simple null</strong>, whereas the more general case is refered to as a <strong>composite null</strong>.</p>

<p>As a general reminder, <strong>statistical hypothesis testing never guarentees optimality</strong>. Namely, the question is never if the null hypothesis is true or not. Rather, it is whether we have sufficient evidence to reject the null hypothesis or not, because the result of a hypothesis test is one of the two possibilities - “reject the null” or “retain the null”.</p>

<p> </p>

<h3 id="512-type-i-error--type-ii-error">5.1.2. Type I error &amp; Type II error</h3>

<p>Since the hypothesis testing is based on random samples, it is always prone to result in incorrect decisions. Regarding this, there are two important concepts in hypothesis testing called as <strong><em>Type I error</em></strong> and <strong><em>Type II error</em></strong>. At a high level, the more critical error among these two are the “type I error”, so often the strategy is to first bound the type I error at a desired level ($\alpha$) and minimize the type II error subsequently.</p>

<center>
  <img src="/images/mathstat/4.png" /> 
  <br />
  <em><span style="color:grey">Results of a statistical test</span></em>
</center>

<p> </p>

<h3 id="513-construction-of-tests">5.1.3. Construction of Tests</h3>

<p>In a nutshell, the canonical way of constructing a test is:
\(\begin{aligned}
&amp;\text{1. Choose a test statistic }T_n = T(X_1, X_2, \dots, X_n) \\[5pt]
&amp;\text{2. Choose a rejection region }R \\[5pt]
&amp;\text{3. If }T_n \in R, \text{ reject }H_0\text{ and otherwise retain }H_0 \\[5pt]
\end{aligned}\)</p>

<p> </p>

<h3 id="514-evaluating-tests">5.1.4. Evaluating Tests</h3>

<p>Then let’s discuss how to evaluate different tests.</p>

<p>Suppose our decision rule for a specific testing problem is that the null hypothesis is rejected when $T(X_1, \dots, X_n) \in R$.</p>

<p>In this setting, we can define the <strong>power function</strong> as:
\(\beta(\theta) = P_\theta\Big( (X_1, \dots, X_n) \in R \Big)\)
Naturally, we would want $\beta(\theta)$ to be small under the null hypothesis $\Theta_0$ and big over $\Theta_1$.</p>

<p>In this sense, the <strong>Neyman-Pearson paradigm</strong> is the following:
\(\begin{aligned}
&amp;\text{1. Fix the type I error  }\alpha \in (0,1) \\[5pt]
&amp;\text{2. Then try to maximize the power }\beta(\theta) \text{ over }\Theta_1, \text{ subject to } \underset{\theta \in \Theta_0}{\text{sup}} \beta(\theta) \leq \alpha
\end{aligned}\)
Tests of this form are called as <strong>level-alpha tests</strong> which guarentees the boundedness of type I error.</p>

<p> </p>

<h4 id="example-a-one-sided-test">Example: A One-sided Test</h4>

<p>Okay, so let’s quickly go over an example.</p>

<p>Suppose $X_1, \dots, X_n \overset{i.i.d.}{\sim} N(\theta, \sigma^2)$, with known $\sigma^2$.</p>

<p>We want to test the <em>one-sided alternative</em> such that:</p>

<center>

$$
\begin{aligned}
H_0&amp;: \theta = \theta_0 \\[5pt]
H_1&amp;: \theta &gt; \theta_0
\end{aligned}
$$

</center>

<p>A natural test statistic we can think of is the scaled average of the samples:</p>

<center> 

$$
T_n(X_1, \dots, X_n) = \frac{\bar X - \theta_0}{\sigma / \sqrt{n}}
$$

</center>

<p>Then, our strategy is to reject the null if $T_n &gt; t$ for some threshold $t$. To choose the optimal threshold, let’s consider the power function:</p>

<center> 

$$
\begin{aligned}
\beta(\theta) &amp;= P_\theta(T_n &gt; t) = P_\theta\Big( 
\frac{\bar X - \theta_0}{\sigma / \sqrt{n}} &gt; t \Big) \\[5pt]
&amp;= P\Big( \frac{\bar X}{\sigma / \sqrt{n}} &gt;  t + \frac{\theta_0}{\sigma/\sqrt{n}} \Big) \\[5pt]
&amp;= P\Big( \frac{\bar X - \theta}{\sigma / \sqrt{n}} &gt;  t + \frac{\theta_0 - \theta}{\sigma/\sqrt{n}} \Big) \\[5pt]
&amp;= P\Big( Z &gt; t + \frac{\theta_0 - \theta}{\sigma/\sqrt{n}} \Big), \quad\quad \because \frac{\bar X - \theta}{\sigma / \sqrt{n}} \sim N(0,1) \text{ by CLT} \\[5pt]
&amp;= 1 - \Phi\Big( t + \frac{\theta_0 - \theta}{\sigma/\sqrt{n}} \Big)
\end{aligned}
$$

</center>

<p>, where $\Phi$ is the cdf of standard normal distribution.</p>

<p>Then, following the Neyman-Pearson paradigm, we can define the optimal threshold $t$ that maximizes the power subject to:</p>

<center> 
$$
\begin{aligned}
&amp;\underset{\theta \in \Theta_0}{\text{sup}}\Big\{  1 - \Phi\Big( t + \frac{\theta_0 - \theta}{\sigma/\sqrt{n}} \Big) \Big\} \leq \alpha \\[10pt]
\Leftrightarrow \quad &amp;1 - \Phi(t) \leq \alpha \\[10pt]
\therefore \quad &amp;t = \Phi^{-1}(1-\alpha)
\end{aligned}
$$
Similarly, for the *two-sided alternative* such that:
$$
\begin{aligned}
H_0&amp;: \theta = \theta_0 \\[5pt]
H_1&amp;: \theta \neq \theta_0
\end{aligned}
$$
The decision rule becomes:
$$
|T_n| &gt; t
$$
 and the corresponding power function is:
$$
\beta(\theta) = P_\theta(T_n &lt; -t) + P_\theta(T_n &gt; t)
$$
which as before can be expanded as:
$$
\begin{aligned}
\beta(\theta) &amp;= P\Big( \frac{\bar X - \theta}{\sigma / \sqrt{n}} &gt;  -t + \frac{\theta_0 - \theta}{\sigma/\sqrt{n}} \Big) + 
P\Big( \frac{\bar X - \theta}{\sigma / \sqrt{n}} &gt;  t + \frac{\theta_0 - \theta}{\sigma/\sqrt{n}} \Big) \\[10pt]
&amp;= \Phi\Big( -t + \frac{\theta_0 - \theta}{\sigma/\sqrt{n}} \Big) + 1 - \Phi\Big( t + \frac{\theta_0 - \theta}{\sigma/\sqrt{n}} \Big)
\end{aligned}
$$
To implement the Neyman-Pearson paradigm under this setting, we just have to plug in the null parameter $\theta_0$ which gives us:
$$
\begin{aligned}
\beta(\theta_0) &amp;= \Phi(-t) + 1 - \Phi(t) \\[5pt]
&amp;= 2 \Phi(-t) \leq \alpha, \quad\quad \because \Phi(t) = 1 - \Phi(-t) \\[10pt]
\Leftrightarrow \quad t &amp;= -\Phi^{-1}(\alpha/2) = \Phi^{-1}(1 - \alpha/2)
\end{aligned}
$$


To summarize what we've been doing so far, we have discussed how to set up a statistical hypothesis testing problem formally, and how we can find the optimal rejection threshold that controls the Type I error while at the same times attains the maximum power, i.e. Neyman-Pearson paradigm.

&nbsp;

## 5.2 Neyman-Pearson Test





---

</center>

<p> </p>

<hr />

<h1 id="reference">Reference</h1>

<ul>
  <li>Casella, G., &amp; Berger, R. L. (2002). <em>Statistical inference.</em> 2nd ed. Australia ; Pacific Grove, CA: Thomson Learning.</li>
</ul>

:ET