I"($<p><a href="https://domug.github.io/2022/06/22/ABTest_multi_layer/">앞서</a>, 여러개의 동시다발적인 실험이 동일한 유저의 모집단을 바탕으로 진행될 수 있도록 설계된 multi-layer experiment의 개념에 대해 살펴보았다. 단 이를 위해서는 한 가지 조건이 만족되어야 했었는데, 이는 바로 실험 간 <strong>“interaction effect”가 발생하지 않아야 한다</strong>는 점이었다.</p>

<p>이와 관련해서 해당 포스트에서는 실험 간 interaction effect의 존재 여부를 어떻게 발견하고 처리할 수 있을지와 관련해서 간단하게 정리해보도록 하겠다.</p>

<p> </p>

<hr />

<h1 id="1-definition-of-interaction-effects">1. Definition of Interaction Effects</h1>

<p>본격적인 내용으로 들어가기에 앞서 실험 간 interaction effect가 무엇인지에 대한 정의를 살펴보자.</p>

<p>설명의 편의를 위해, 기능 A와 기능 B 중 어떤게 더 높은 수익을 내는지를 비교하기 위한 실험이 있다고 해보자. 이 때, 기능 A을 적용했을 때의 수익 증가율을 $a$, 기능 B에서의 수익 증가율을 $b$ 라고 하겠다. 물론 $a$ 와 $b$ 는 우리가 실험을 통해 추론하고자 하는 모수이기 때문에 실제 참 값을 알 수는 없다.</p>

<p>이러한 맥락에서 해당 값들을 추정하기 위해 기능 A와 B 각각을 대조군과 비교하는 실험을 한번씩 진행했고, 그 결과로 $a$와 $b$에 대해 2%와 5%라는 추정치를 얻었다고 가정하겠다.</p>

<center>
  <img src="/images/abtest/65.png" width="350" height="250" /> 
 <br />
 <em><span style="color:grey"></span></em>
</center>

<p> </p>

<p>위와 같은 상황에서, 새로운 기능 A를 도입할 경우 수익이 2% 정도 증가하고, B를 도입할 경우 수익이 5% 정도 도입할 것이라고 결론내릴 수 있다.</p>

<p>한편, 만약 기능 A와 B “둘 다”를 도입할 경우에 기대 수익은 어떻게 될까? 이와 관련해서, 만약 두 기능 간 interaction effect가 <strong>“없다면”</strong>, A와 B를 동시에 적용함으로써 얻을 수 있는 수익의 증가율은 대략 <strong>7%</strong> 정도가 될 것이라고 추측해볼 수 있다. 반면에, 만약 두 기능간 interaction effect가 <strong>“있다면”</strong>, 두 기능을 동시에 적용해서 얻을 수 있는 수익의 증가율은 더 이상 7%가 아니게 된다. 만약 양의 상관관계가 있을 경우 수익의 증가율은 7%보다 커지게 될 것이며, 음의 상관관계가 있는 경우 7%보다 감소할 것이다.</p>

<p> </p>

<p><strong>&lt;interaction effect X&gt;</strong></p>

<center>
  <img src="/images/abtest/66.png" width="350" height="250" /> 
 <br />
 <em><span style="color:grey"></span></em>
</center>

<p> </p>

<p><strong>&lt;interaction effect O&gt;</strong></p>

<center>
  <img src="/images/abtest/67.png" width="350" height="250" /> 
 <br />
 <em><span style="color:grey"></span></em>
</center>

<p> </p>

<p>이처럼 interaction effect가 있는 경우 기능 A와 B 모두를 적용받는 유저들의 수익 증가율은 단순히 각 기능에서의 효과 $a, b$ 를 더한 값이 아니게 된다. 더불어 이러한 interaction effect 로 인해 실험의 결과가 왜곡되는 현상이 발생할 수 있게 된다.</p>

<p>이러한 맥락에서 다시 한번 <strong>무작위 배정</strong>의 중요성이 부각되는데, 그 이유는 만약 무작위 배정이 완벽하게 수행된다면 기능 A, B를 동시에 적용받는 유저들이 대조군과 시험군에 골고루 분포되어 interaction effect로 인한 bias가 전체적으로 보정되기 때문이다. 즉, 무작위 배정만 완벽하다면 우리는 개별적인 실험에서 성능에 대한 <strong>비편향추정치 (unbiased estimate)</strong>를 얻을 수 있다. <a href="https://support.optimizely.com/hc/en-us/categories/4410287901197-Experimentation">(이미지 출처)</a></p>

<center>
  <img src="/images/abtest/68.png" width="700" height="500" /> 
 <br />
 <em><span style="color:grey"></span></em>
</center>

<p> </p>

<p>그렇다면 randomization algorithm만 제대로 기능한다면 실험의 결과를 제대로 구할 수 있는데, 굳이 interaction effect를 신경쓸 필요가 있을지에 대한 궁금증이 생길 수 있다. 이와 관련해서 많은 실험 플랫폼들이 interaction effect를 찾아내기 위해 고군분투하는 주된 이유는, 바로 유저의 부정적인 경험을 야기할 수 있는 <strong>negative interaction effect</strong>를 찾아내기 위함이다.</p>

<p>가령, 페이스북 광고의 “폰트 색깔”과 “배경 색깔”에 대한 실험을 진행한다고 할 때, 만약 특정한 그룹의 유저들이 빨간색 폰트와 빨간색 배경의 조합에 노출될 경우 해당 유저들은 끔찍한 경험을 하게 될 것 이다. 물론 이렇게 직관적으로 예상이 가능한 interaction effect는 사전에 실험의 관리자에 의해 필터링이 될 것이나, 실제로는 어떠한 기능들의 조합이 유저에게 부정적인 경험을 줄지 사전에 알 수 없는 경우가 많기 때문에 어떠한 상황에서 interaction effect가 안 좋은 쪽으로 발생하는지를 미리 규명하고 싶은 니즈가 발생하게 된다.</p>

<p> </p>

<hr />

<h1 id="2-handling-interaction-effects">2. Handling Interaction Effects</h1>

<p>그렇다면 실제 실험에서 interaction effect가 존재하는지 여부를 직/간접적으로 파악할 수 있는 몇가지 방법들에 대해 살펴보도록 하자.</p>

<p> </p>

<h3 id="isolating-experiments">Isolating Experiments</h3>

<p>사실 당연한 이야기이지만, interaction effect를 방지하기 위한 가장 확실한 방법은 interaction effect 자체가 발생될 수 없도록 실험 플랫폼을 설계하는 것이다. 이를 <strong>“isolated experiments”</strong>라고 표현하는데, 핵심은 특정 실험에 참가한 유저들이 또 다른 실험에 동시에 참가할 수 없게끔 버켓을 정의하는 것이다 (i.e. single-layer experiments).</p>

<p>단, 이러한 방법은 <a href="https://domug.github.io/2022/06/22/ABTest_multi_layer/">앞선 포스트</a>에서 살펴본 것처럼 실험이 많아지는 경우 스케일링 문제가 발생한다는 것과 검정력이 낮아진다는 단점 때문에 본질적인 한계점을 갖고 있다. 이와 관련해서 해당 <a href="https://blog.statsig.com/embracing-overlapping-a-b-tests-and-the-danger-of-isolating-experiments-cb0a69e09d3">아티클</a>에서는 다음과 같은 어쩔 수 없는 상황을 제외하고는 가급적이면 multi-layer experiment design을 사용할 것을 권고하고 있다.</p>

<ol>
  <li>동일한 유저가 서로 다른 실험에 배정되는 것이 물리적으로 불가능한 경우 (추천 알고리즘 1 vs 추천 알고리즘 2)</li>
  <li><strong>유저에게 부정적인 경험을 발생시킬 수 있는 경우</strong></li>
  <li>매우 정확한 결과 도출이 필요한 경우</li>
</ol>

<p> </p>

<h3 id="manual-inspection">Manual Inspection</h3>

<p>여러 실험 플랫폼들에서 경험적으로 발견된 것 중에 하나는, 실제 실험에서 우리가 전혀 예상하지 못한 방향으로 상당한 interaction effect가 발생하는 경우는 매우 드물다는 점이다 (<a href="https://blog.statsig.com/embracing-overlapping-a-b-tests-and-the-danger-of-isolating-experiments-cb0a69e09d3">참고</a>).</p>

<p>특히나 유저에게 부정적인 경험을 초래할 만한 interaction effect의 경우는 직관적인 측면에서 미리 예측하고 대응할 수 있는 경우가 많다. 가령 아래와 같은 실험에서 파란색 버튼과 파란색 배경 각각에 대해서는 성능이 좋았다고 하더라도, 만약 두 기능을 동시에 적용할 경우 상당한 문제가 발생할 것이라는 점은 그 누구라도 쉽게 예측할 수 있을 것이다.</p>

<center>
  <img src="/images/abtest/69.png" width="400" height="300" /> 
 <br />
 <em><span style="color:grey"></span></em>
</center>

<p> </p>

<p>이러한 측면에서 많은 회사들은 실험을 관리하는 별도의 팀 또는 TF를 구성한다고 한다. 해당 팀원들은 동시 다발적으로 진행되는 실험들을 관리하고, 새로운 실험에 대한 로드맵을 파악한 다음 어떠한 부분에서 기존에 진행되고 있는 실험들과 충돌이 발생할 수 있는지를 파악하는 업무를 수행하게 됩니다. 그리고 만약 충돌이 발생할 것 같은 실험의 경우는 별도로 isolation을 진행한 다음 실험을 수행할 수 있도록 지원합니다.</p>

<p>이런 식으로 매뉴얼하게 실험들을 관리하는 것을 통해 multi-layer 플랫폼의 안정성을 보장하는 것이 많은 플랫폼들에서의 공통적인 방식인 것 같습니다.</p>

<p> </p>

<hr />

<p>&lt;/center&gt;</p>

<p> </p>

<hr />

<h1 id="reference">Reference</h1>

<ul>
  <li>Casella, G., &amp; Berger, R. L. (2002). <em>Statistical inference.</em> 2nd ed. Australia ; Pacific Grove, CA: Thomson Learning.</li>
</ul>

:ET