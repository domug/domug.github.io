I"^$<p>이번 포스트에서는 통계학을 접해 본 사람이라면 누구나 한번쯤은 들어봤을 법한 <strong>p-value</strong>에 대해서 리뷰해보도록 하겠다.</p>

<p>P-value는 통계적 가설 검정에서 가장 핵심적인 역할을 맡고 있다고 해도 과언이 아니다. 흔히 그 값이 0.05보다 작으면 “실험이 유의하다” 정도로 공식처럼 암기하고 있는 경우가 많지만, 막상 개념적으로 그 의미를 설명하기에는 까다로울 수 있다. 실제로 예전에 통계학개론 수업을 들을 때 조부모님께 p-value를 설명하는 것이 과제로 나온적이 있었다..</p>

<p>그만큼 통계학 전공자들에게도 p-value를 명쾌하게 설명하기란 쉬운 일이 아닌데, 그 이유는 애시당초에 개념 자체가 직관적이지 않은 부분도 있고, 더불어 p-value를 제대로 설명하려면 통계학이 무엇을 하려는 학문인지에 대한 명확한 이해가 필요하기 때문이다.</p>

<p>이러한 측면에서 해당 포스트에서는 간단하게 통계학의 세계관을 훒어본 다음, p-value의 정확한 의미에 대해서 이야기해보도록 하겠다.</p>

<p> </p>

<hr />

<h2 id="1-과학의-발전과-통계학의-탄생">1. 과학의 발전과 통계학의 탄생</h2>

<p>본격적인 이야기에 들어가기에 앞서, 간략하게 통계학이 탄생하게 된 배경에 대해서 살펴보자.</p>

<p>르네상스와 16세기의 종교 개혁 등을 거치면서, 인간의 사회는 점차 기존 신 중심의 세계관에서 논리성, 합리성이 강조되는 <strong>과학 중심의 세계관</strong>으로 변화하기 시작했다. 후세에 “<strong>과학 혁명”</strong> 이라고도 불리는 이 패러다임의 중심에는 우주 만물의 변하지 않는 “<strong>본질적인 진리</strong>“에 대한 호기심이 있었다. 예를 들어, 뉴턴과 같은 천문물리학자들은 행성들의 움직임이 복잡한 방정식으로 표현되는 정확한 공식에 의해 발생한다고 믿었고, 이를 밝혀내기 위해 상당한 노력을 기울였다. 이러한 측면에서 이를 <strong>결정론적 세계관</strong>이라고 부르기도 한다.</p>

<center>
  <img src="/images/abtest/4.jpg" width="250" height="200" /> 
 <br />
 <em><span style="color:grey">뉴턴의 중력의 법칙</span></em>
</center>

<p> </p>

<p>하지만 그들의 노력에도 불구하고, 특정한 현상을 완벽하게 설명하는 공식은 찾을 수가 없었다. 모든 관측치들은 필연적으로 설명되지 않는 “<strong>불확실성 (오차)”</strong> 을 포함하고 있었으며, 당시의 과학자들은 그 이유가 망원경과 같은 측정 도구의 부정확함 때문이라고 생각했다.</p>

<p>시간이 흘러 물리학을 포함한 여러 과학의 분야에서 점점 더 정밀한 도구와 발전된 방법론이 등장했음에도 불구하고, 여전히 측정 대상에 대한 오차는 없어지지 않았다. 어떻게 하면 이러한 불확실성을 줄일 수 있을까 골머리를 앓던 와중, 사람들은 본질적인 의문을 제기하기 시작했다 - “<strong>어쩌면 모든 현상에 불확실성이 본질적으로 내재되어 있는 것은 아닐까?</strong>” 라는 생각을.</p>

<p>이러한 발상의 전환은 궁극적으로 통계학이라는 학문을 탄생시키는 계기가 되었다고 해도 과언이 아니다. 혹자는 이를 <strong>“통계적 혁명”</strong>이라고 부르기도 하는데, 그 아이디어를 좀 더 자세히 알아보도록 하자.</p>

<p> </p>

<h2 id="2-통계학의-세계관">2. 통계학의 세계관</h2>

<p>18세기까지의 과학을 지배하던 결정론적 세계관과는 반대로, 통계학은 <a href="https://namu.wiki/w/카오스 이론">”</a><strong><a href="https://namu.wiki/w/카오스 이론">카오스 이론</a></strong><a href="https://namu.wiki/w/카오스 이론">”</a> 을 바탕으로 하는 <strong>확률적인 세계관</strong>을 표방한다. 즉, 우리에게 관측되는 데이터는 여러 요인들의 복합적인 상호작용으로 인한 <strong>“오차”</strong>라는 불확실성을 포함한 값이라는 생각이다.</p>

<center>
  <img src="/images/abtest/5.jpg" width="250" height="200" /> 
 <br />
 <em><span style="color:grey">뉴턴의 중력의 법칙</span></em>
</center>

<p>그렇기 때문에 통계학에서는 관찰된 데이터 그 자체는 관심 대상이 아니게 된다. 이보다 더 중요한 것은 관찰된 데이터들을 발생시킨 “매커니즘” 이고, 통계학에서는 이를 “<strong>확률 분포</strong>” 로 정의하며 이러한 맥락에서 과학의 목표는 현상들에 내재된 확률 분포를 규명하는 것이 된다.</p>

<p>그렇다면 이렇게 내재된 확률 분포는 어떻게 밝혀낼 수 있을까? 통계학의 아버지라고 불리는 칼 피어슨 (Karl Pearson) 이 제시한 관점에 따르면, 모든 확률 분포는 “<strong>모수 (parameter)</strong>“라고 불리는 다음의 4가지 값들에 의해 정의된다.</p>

<ol>
  <li>
    <p><strong>평균 (mean)</strong>: 산발적으로 흩어져 있는 측정 자료들의 중심</p>
  </li>
  <li>
    <p><strong>표준편차 (standard deviation)</strong>: 측정 자료들이 평균을 중심으로 얼마나 멀리 있는지 정도</p>
  </li>
  <li>
    <p><strong>왜도 (symmetry)</strong>: 측정 자료들이 평균을 기준으로 한쪽으로 쏠려있는 정도 (skewness)</p>
  </li>
  <li>
    <p><strong>첨도 (kurtosis)</strong>: 드물게 발생하는 측정값들이 평균에서 얼마나 멀리 떨어져 있는지 정도 (tailedness)</p>
  </li>
</ol>

<p> </p>

<p>이러한 프레임워크를 바탕으로 피어슨은 모든 데이터가 <strong>특정한 현상의 확률 분포에서 랜덤하게 발생되는 값</strong>이라고 생각했고, 그의 생각은 점차 과학을 지배하기 시작했다. 다시 말해, 관심 현상에 대한 확률 분포를 찾아내는 것, 즉 <strong>모수를 추정하는 것</strong>이 과학의 궁극적인 목표가 되기 시작했는데, 여기서 한가지 문제점은 <strong>모수의 참 값을 실제로 알 수가 없다</strong>는 점이다.</p>

<p>바로 이 지점이 통계학이라는 학문이 탄생하게 된 직접적인 계기이다. 통계학에서는 추정하고자 하는 모수에 대한 “그럴싸한” 값을 관측된 데이터 (표본) 를 바탕으로 제시하려는 것이 그 핵심적인 관심사라고 할 수 있다. 사실 현대 통계학에서 모수의 개념은 앞서 설명한 것보다 훨씬 확장되었으나, 그 본질적인 아이디어는 동일하다고 생각한다.</p>

<center>
  <img src="/images/abtest/3.png" /> 
 <br />
 <em><span style="color:grey">통계적 추론의 프레임워크</span></em>
</center>

<p> </p>

<p>정리하자면, <strong>우리에게 관측되는 모든 데이터는 모수들에 의해 정의되는 확률 분포로부터 랜덤하게 발생된다</strong>는 것이 지금까지의 핵심 내용이라고 할 수 있겠다. 편의상 통계학자들은 경험적으로 여러 현상들에서 자주 관측되는 분포들을 미리 정의해두었는데, 이를 <strong>표준 확률 분포</strong>라고 부르고 우리가 잘 아는 <strong>정규분포</strong>, <strong>이항분포</strong>, <strong>포아송분포</strong> 등이 대표적인 분포들이다.</p>

<p>이 과정에서 마치 유니콘과 같은 모수를 나름 합리적으로 추정하려는 시도가 통계학이며, 이 과정을 좀 더 세분화하면 다음과 같이 통계적 “<strong>추정</strong>”, “<strong>검정</strong>”, “<strong>예측</strong>“의 세가지 범주로 구분할 수 있다.</p>

<blockquote>
  <ul>
    <li>
      <p><strong>추정</strong>: 모수의 그럴싸한 값을 구하는 것</p>
    </li>
    <li>
      <p><strong>검정</strong>: 모수에 의한 어떠한 가설 (statement) 에 대해 의사결정을 내리는 것</p>
    </li>
    <li>
      <p><strong>예측</strong>: 모수로 인해 발생할 수 있는 미래의 값을 구하는 것</p>
    </li>
  </ul>

</blockquote>

<p>이제 본격적으로 p-value를 살펴보기 위한 준비가 끝났다. 이후 내용에서는 두번째 “<strong>검정</strong>“에 집중해서 p-value에 의미와 역할에 대해 구체적으로 살펴보도록 하겠다.</p>

<p>cf) 사족이지만, 해당 분류에서 세번째 “<strong>예측</strong>“에 특화된 학문이 바로 <strong>머신러닝</strong>과 <strong>딥러닝</strong>이다.</p>

<p>+ 편의상 통계학자들은 경험적으로 여러 현상들에서 자주 관측되는 분포들을 미리 정의해두었습니다. 이를 표준 확률 분포라고 부르고 대표적으로는 우리가 잘 아는 <strong>정규분포</strong>, <strong>이항분포</strong>, <strong>포아송분포</strong> 등이 있겠습니다.</p>

<p>&lt;/center&gt;</p>

<p> </p>

<hr />

<h1 id="reference">Reference</h1>

<ul>
  <li>Casella, G., &amp; Berger, R. L. (2002). <em>Statistical inference.</em> 2nd ed. Australia ; Pacific Grove, CA: Thomson Learning.</li>
</ul>

:ET